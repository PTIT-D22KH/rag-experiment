{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe24520-6c42-4c83-bd93-0c2715a62dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from requests.exceptions import HTTPError\n",
    "import time\n",
    "# from groq.exceptions import RateLimitError\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c46a9d83-cb04-4200-81d4-96998653ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "client =  Groq(api_key = os.environ['GROQ_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f26bc4-5643-4e5d-b2b0-ba9099d45552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "19fc9924-77c0-47a7-a6c0-8eed58051fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids1.json', 'rt') as f_in:\n",
    "    documents1 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e2e0b9c4-7960-48c2-821d-f8d586358b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids2.json', 'rt') as f_in:\n",
    "    documents2 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bc9cf65b-46bd-47d8-b2e5-ee882937f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids3.json', 'rt') as f_in:\n",
    "    documents3 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "032d23cd-9fbe-41a5-b4bd-0b35bad8c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids4.json', 'rt') as f_in:\n",
    "    documents4 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3014f8f1-332d-4341-b96a-6141c2e7b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids5.json', 'rt') as f_in:\n",
    "    documents5 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8b7cd2fd-7b45-4b56-a22a-2f4c2ebf8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documents1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "400f037a-2f6b-40ed-a6c9-148fd457e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.extend(documents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4665970c-9c2f-48c6-9a1b-389619af902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.extend(documents3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e511a3fb-9d58-4087-8aa4-41972b79aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.extend(documents4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "364ecc8e-e73b-492b-b5ac-034621c469ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.extend(documents5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d41e8806-ddf2-4847-a295-1181054c76fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6089"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "160e34ec-0ffc-4e98-9440-c4d7618ca528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0845ba74-d2e9-4593-a2cf-e323fd8021f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['group', 'context', 'question', 'answer', 'id'])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents1[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7749153a-333f-46f9-8a2e-cc7fbbaa947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate my assistant who works with me in a Q and A project .\n",
    "Formulate 5 questions people might ask based on the record. The record\n",
    "should contain the answer to the questions, and the questions should be complete and not too short.\n",
    "If possible, use as fewer words as possible from the record. Make sure the questions should be in Vietnamese and the output can be parsed into json format.\n",
    "\n",
    "The record:\n",
    "\n",
    "question: {question}\n",
    "answer: {answer}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "[\"question1\", \"question2\", ..., \"question5\"]\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f4d9b362-29a6-4a41-8547-e90ffeb7d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    # Create a new dictionary excluding the first key-value pair\n",
    "    # doc_items = list(doc.items())[1:]  # Skip the first item\n",
    "    # doc_filtered = dict(doc_items)\n",
    "\n",
    "    # prompt = prompt_template.format(**doc_filtered)\n",
    "    prompt = prompt_template.format(**doc)\n",
    "    # print(prompt)\n",
    "    retries = 5\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model='Gemma2-9b-It',\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            json_response = response.choices[0].message.content\n",
    "            return json_response\n",
    "        except HTTPError as e:\n",
    "            if e.response.status_code == 429:  # Rate limit error\n",
    "                retry_after = float(e.response.json()['error']['message'].split('in ')[-1].split('s')[0])\n",
    "                time.sleep(retry_after)\n",
    "            else:\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            if i < retries - 1:\n",
    "                time.sleep(2 ** i)  # Exponential backoff\n",
    "            else:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "24ad98bd-d031-49f7-a6c5-559b3cb6b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_progress(pool, seq, f):\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seq)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for el in seq:\n",
    "            future = pool.submit(f, el)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3976b0d8-2e24-492e-add5-d810b02ed7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize ThreadPoolExecutor\n",
    "pool = ThreadPoolExecutor(max_workers=6)\n",
    "\n",
    "# Process documents in parallel\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ebecb59b-f587-4984-9610-4c3994439130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(doc):\n",
    "    doc_id = doc['id']\n",
    "    if doc_id in results:\n",
    "        return None\n",
    "\n",
    "    questions = generate_questions(doc)\n",
    "    return (doc_id, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd268002-4bc2-48ea-a7e2-f7c34ccc2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[:30], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd1f82-cfb3-467b-b1c6-54a35a6576c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Print or save the results as needed\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d84176c6-5103-436c-9deb-6886dfe9d9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87cf08f9-6449-4721-9ccf-c6f87dedbfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from collections import defaultdict\n",
    "\n",
    "# hashes = defaultdict(list)\n",
    "\n",
    "# for doc in documents1:\n",
    "#     doc_id = doc['id']\n",
    "#     hashes[doc_id].append(doc)\n",
    "# # hashes['75fafd29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3027c258-827e-4687-b9aa-4c2155dab7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len = 0\n",
    "# for hash in hashes:\n",
    "#     print(hash)\n",
    "#     len += 1\n",
    "#     if len == 30:\n",
    "#         break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e25edddf-650a-422e-8c98-13e69470d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for result in results:\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35939842-bc41-4886-b015-fed5e2ba86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth1.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1aefd32-cbcc-4984-ad4b-9fb29b3ee1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth1.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "100523ac-6c8d-4307-8c04-86e943320057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fe24cfb-791d-4340-8992-af7e53bbd92e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 30/30 [00:03<00:00,  9.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30:30*2], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c543e8d7-4efd-4bad-a3a2-cca2693c8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_n_items(d, n):\n",
    "    # Convert dictionary items to a list\n",
    "    items = list(d.items())\n",
    "    # Slice the list to get the last n items\n",
    "    last_n_items = items[-n:]\n",
    "    # Convert the sliced list back to a dictionary\n",
    "    return dict(last_n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4fcd43a-0f7f-4ac3-8a4e-13a2cebb26f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_30_items = get_last_n_items(results, 30)\n",
    "len(last_30_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30063159-5dd6-452b-9f3f-2b9f879f9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth2.pkl', 'wb') as file:\n",
    "    pickle.dump(last_30_items, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adbb6439-bc5f-4cf8-99f2-60fb5f430fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth2.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce4bfa-b708-48db-b251-114f92d02cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d714e3e6-9523-4d5b-bbc1-daa2c37041d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:02<00:00, 10.34it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30*2:30*3], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31b041c1-ee55-41ed-a184-8fc07733dafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a1011b8-9b7d-409d-ae7f-d48ef9c1ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth3.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2a14cf1-9e4d-45f5-9944-ed5b5d5fc015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 30/30 [00:38<00:00,  1.29s/it]\n",
      " 40%|████████████████████▍                              | 12/30 [00:12<00:27,  1.53s/it]"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30*3:30*4], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73d7dede-4247-4ab8-bda4-1cf0b4302b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth4.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "623e0abf-489a-42ed-bcd3-bdb33abc4905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 30/30 [00:50<00:00,  1.68s/it]\n",
      " 17%|████████▋                                           | 5/30 [00:04<00:30,  1.20s/it]"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30*4:30*5], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth5.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3e7f02e-17d7-4da8-a794-96fd8ae54e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 30/30 [00:13<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30*5:30*6], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth6.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d4e70b8-b2c9-401d-b8d9-7372c458d235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 30/30 [00:52<00:00,  1.75s/it]\n",
      "100%|█████████████████████████| 17/17 [00:02<00:00,  7.52it/s]0 [00:03<00:00,  9.59it/s]"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30*6:30*7], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth7.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9825dc5-5cbd-43af-9e6e-94ae65bdfce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 30/30 [00:49<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30*7:30*8], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth8.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc9349d9-b6bb-4986-9f1b-c1e6c1db89c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 30/30 [00:44<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30*8:30*9], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth9.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41bb5dc5-cd23-4300-a2ad-b5236cc3cc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 30/30 [00:03<00:00,  7.54it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30*9:30*10], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth10.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8d71ad6-40ce-4f88-8efc-d255d80b594e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30*10:30*11], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth11.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "578b1f34-1d12-4bc1-8bc2-b696cf3166c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 30/30 [00:37<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30*11:30*12], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth12.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ee28792-5c90-4c65-90a6-b852f93e4a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 30/30 [00:23<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[30*12:30*13], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth13.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07cde4c4-bc14-4ef8-9c00-d13cd194061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "390 420\n",
      "420 450\n",
      "450 480\n",
      "480 510\n",
      "510 540\n",
      "540 570\n",
      "570 600\n",
      "600 630\n",
      "630 660\n",
      "660 690\n",
      "690 720\n",
      "720 750\n",
      "750 780\n",
      "780 810\n",
      "810 840\n",
      "840 870\n",
      "870 900\n",
      "900 930\n",
      "930 960\n",
      "960 990\n",
      "990 1020\n",
      "1020 1050\n",
      "1050 1080\n",
      "1080 1110\n",
      "1110 1140\n",
      "1140 1170\n",
      "1170 1200\n"
     ]
    }
   ],
   "source": [
    "# Process documents in chunks of 30\n",
    "chunk_size = 30\n",
    "start_chunk = 13  # Starting chunk index\n",
    "end_chunk = (len(documents1) // chunk_size)  # Ending chunk index\n",
    "print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    chunk = documents1[chunk_start:chunk_end]\n",
    "    print(chunk_start, chunk_end)\n",
    "\n",
    "#     # Use map_progress to process documents\n",
    "#     processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "#     # Store the results incrementally\n",
    "#     for result in processed_results:\n",
    "#         if result is not None:\n",
    "#             doc_id, questions = result\n",
    "#             results[doc_id] = questions\n",
    "\n",
    "#     # Save the results to a file\n",
    "#     file_name = f'../data/vietnamese_rag/ground_truth_data/ground_truth{i}.pkl'\n",
    "#     with open(file_name, 'wb') as file:\n",
    "#         pickle.dump(results, file)\n",
    "\n",
    "#     # Print out the results\n",
    "#     print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "#     print(results)\n",
    "\n",
    "#     # Wait for 1 minute to reset rate limit\n",
    "#     time.sleep(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef6b44-6c00-47d3-b6f6-e9c895e539ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process documents in chunks of 30\n",
    "chunk_size = 30\n",
    "start_chunk = 14  # Starting chunk index\n",
    "end_chunk = (len(documents1) // chunk_size)  # Ending chunk index\n",
    "print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    chunk = documents1[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_data/ground_truth{i + 1}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e722f5f1-7731-441c-a8b2-b11d6d7fc95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 17/17 [00:02<00:00,  7.63it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents1[1200:], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth41.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d28131e-cca5-4438-b025-94a12947c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids2.json', 'rt') as f_in:\n",
    "    documents2 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7649424d-10f2-4a1c-b6d1-7f5e9717bec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cb62cc0-adb1-49f8-8803-5f8ecbfebbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "42 0 30\n",
      "43 30 60\n",
      "44 60 90\n",
      "45 90 120\n",
      "46 120 150\n",
      "47 150 180\n",
      "48 180 210\n",
      "49 210 240\n",
      "50 240 270\n",
      "51 270 300\n",
      "52 300 330\n",
      "53 330 360\n",
      "54 360 390\n",
      "55 390 420\n",
      "56 420 450\n",
      "57 450 480\n",
      "58 480 510\n",
      "59 510 540\n",
      "60 540 570\n",
      "61 570 600\n",
      "62 600 630\n",
      "63 630 660\n",
      "64 660 690\n",
      "65 690 720\n",
      "66 720 750\n",
      "67 750 780\n",
      "68 780 810\n",
      "69 810 840\n",
      "70 840 870\n",
      "71 870 900\n",
      "72 900 930\n",
      "73 930 960\n",
      "74 960 990\n",
      "75 990 1020\n",
      "76 1020 1050\n",
      "77 1050 1080\n",
      "78 1080 1110\n",
      "79 1110 1140\n",
      "80 1140 1170\n",
      "81 1170 1200\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 30\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents2) // chunk_size)  # Ending chunk index\n",
    "print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    print(i + 42, chunk_start, chunk_end)\n",
    "    # chunk = documents1[chunk_start:chunk_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b9e00-1d8d-4e1e-8471-4e338b99f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 30\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents2) // chunk_size)  # Ending chunk index\n",
    "print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    # print(i + 42, chunk_start, chunk_end)\n",
    "    chunk = documents2[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_data/ground_truth{i + 42}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e3e37c7-8ce0-4c82-847c-820c9686c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 17/17 [00:05<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents2[1200:], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth82.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f383090-6c4c-4cf8-ba64-4009d92e2e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids3.json', 'rt') as f_in:\n",
    "    documents3 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248f646-ee1e-4c27-8ee9-431e98ce52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 30\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents3) // chunk_size)  # Ending chunk index\n",
    "print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    # print(i + 42, chunk_start, chunk_end)\n",
    "    chunk = documents3[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_data/ground_truth{i + 83}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85f78de6-e9d2-4c9b-bbd2-ff2762d34986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# # Use map_progress to process documents\n",
    "# processed_results = map_progress(pool, documents3[1200:], process_document)\n",
    "\n",
    "# # Store the results\n",
    "# for result in processed_results:\n",
    "#     if result is not None:\n",
    "#         doc_id, questions = result\n",
    "#         results[doc_id] = questions\n",
    "# with open('../data/vietnamese_rag/ground_truth_data/ground_truth84.pkl', 'wb') as file:\n",
    "#     pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "466495ea-510a-4cf3-be72-ab1c5178704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/vietnamese_rag/documents-with-ids4.json', 'rt') as f_in:\n",
    "#     documents4 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88d2de70-0ddc-446e-b762-6d4c15cbb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_size = 30\n",
    "# start_chunk = 0 # Starting chunk index\n",
    "# end_chunk = (len(documents4) // chunk_size)  # Ending chunk index\n",
    "# print(end_chunk)\n",
    "# for i in range(start_chunk, end_chunk):\n",
    "#     results = {}\n",
    "#     chunk_start = i * chunk_size\n",
    "#     chunk_end = chunk_start + chunk_size\n",
    "#     # print(i + 42, chunk_start, chunk_end)\n",
    "#     chunk = documents4[chunk_start:chunk_end]\n",
    "\n",
    "#     # Use map_progress to process documents\n",
    "#     processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "#     # Store the results incrementally\n",
    "#     for result in processed_results:\n",
    "#         if result is not None:\n",
    "#             doc_id, questions = result\n",
    "#             results[doc_id] = questions\n",
    "\n",
    "#     # Save the results to a file\n",
    "#     file_name = f'../data/vietnamese_rag/ground_truth_data/ground_truth{i + 85}.pkl'\n",
    "#     with open(file_name, 'wb') as file:\n",
    "#         pickle.dump(results, file)\n",
    "\n",
    "#     # Print out the results\n",
    "#     print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "#     print(results)\n",
    "\n",
    "#     # Wait for 1 minute to reset rate limit\n",
    "#     time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d49f00ab-70bd-45e2-ab2b-505c92b208ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 17/17 [00:02<00:00,  6.71it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents3[1200:], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth123.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a3d1332-d307-436b-bd00-16e33e162b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids4.json', 'rt') as f_in:\n",
    "    documents4 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fdab3f-fd68-4ea9-be6a-dd5f6b726597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunk_size = 30\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents4) // chunk_size)  # Ending chunk index\n",
    "print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    # print(i + 42, chunk_start, chunk_end)\n",
    "    chunk = documents4[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_data/ground_truth{i + 124}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    # print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0bc24f56-72e8-4feb-b976-a545a3296573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "124 0 30\n",
      "125 30 60\n",
      "126 60 90\n",
      "127 90 120\n",
      "128 120 150\n",
      "129 150 180\n",
      "130 180 210\n",
      "131 210 240\n",
      "132 240 270\n",
      "133 270 300\n",
      "134 300 330\n",
      "135 330 360\n",
      "136 360 390\n",
      "137 390 420\n",
      "138 420 450\n",
      "139 450 480\n",
      "140 480 510\n",
      "141 510 540\n",
      "142 540 570\n",
      "143 570 600\n",
      "144 600 630\n",
      "145 630 660\n",
      "146 660 690\n",
      "147 690 720\n",
      "148 720 750\n",
      "149 750 780\n",
      "150 780 810\n",
      "151 810 840\n",
      "152 840 870\n",
      "153 870 900\n",
      "154 900 930\n",
      "155 930 960\n",
      "156 960 990\n",
      "157 990 1020\n",
      "158 1020 1050\n",
      "159 1050 1080\n",
      "160 1080 1110\n",
      "161 1110 1140\n",
      "162 1140 1170\n",
      "163 1170 1200\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 30\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents4) // chunk_size)  # Ending chunk index\n",
    "print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    print(i + 124, chunk_start, chunk_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea9145a5-9dd1-4ee7-8048-80f97cc307d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 17/17 [00:02<00:00,  6.55it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents4[1200:], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth164.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff1fac58-4aff-4946-8f82-6b44b9ae4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids5.json', 'rt') as f_in:\n",
    "    documents5 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53efc314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1221"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1402fb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "165 0 30\n",
      "166 30 60\n",
      "167 60 90\n",
      "168 90 120\n",
      "169 120 150\n",
      "170 150 180\n",
      "171 180 210\n",
      "172 210 240\n",
      "173 240 270\n",
      "174 270 300\n",
      "175 300 330\n",
      "176 330 360\n",
      "177 360 390\n",
      "178 390 420\n",
      "179 420 450\n",
      "180 450 480\n",
      "181 480 510\n",
      "182 510 540\n",
      "183 540 570\n",
      "184 570 600\n",
      "185 600 630\n",
      "186 630 660\n",
      "187 660 690\n",
      "188 690 720\n",
      "189 720 750\n",
      "190 750 780\n",
      "191 780 810\n",
      "192 810 840\n",
      "193 840 870\n",
      "194 870 900\n",
      "195 900 930\n",
      "196 930 960\n",
      "197 960 990\n",
      "198 990 1020\n",
      "199 1020 1050\n",
      "200 1050 1080\n",
      "201 1080 1110\n",
      "202 1110 1140\n",
      "203 1140 1170\n",
      "204 1170 1200\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 30\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents5) // chunk_size)  # Ending chunk index\n",
    "print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    print(i + 165, chunk_start, chunk_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15abca26-e367-4163-9398-f81c4aa1e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 30\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents5) // chunk_size)  # Ending chunk index\n",
    "print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    # print(i + 42, chunk_start, chunk_end)\n",
    "    chunk = documents5[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_data/ground_truth{i + 165}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    # print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "942c168a-3034-40f7-bcb9-efb6381e43a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 30/30 [00:03<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 39 processed and saved to ../data/vietnamese_rag/ground_truth_data/ground_truth204.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 21/21 [00:23<00:00,  2.95s/it]"
     ]
    }
   ],
   "source": [
    "chunk_size = 30\n",
    "start_chunk = 39 # Starting chunk index\n",
    "end_chunk = (len(documents5) // chunk_size)  # Ending chunk index\n",
    "print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    # print(i + 165, chunk_start, chunk_end)\n",
    "    chunk = documents5[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_data/ground_truth{i + 165}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    # print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9adedcf1-cc65-4eb4-9859-88c7b01bbf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 21/21 [00:23<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents5[1200:], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth205.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e86d77f4-65dc-466e-ae00-8d0301f880f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON for document 64016d4f: Invalid control character at: line 5 column 49 (char 303)\n",
      "Error decoding JSON for document df658334: Invalid control character at: line 1 column 338 (char 337)\n"
     ]
    }
   ],
   "source": [
    "parsed_results = {}\n",
    "for doc_id, json_questions in results.items():\n",
    "    try:\n",
    "        parsed_questions = json.loads(json_questions)\n",
    "        parsed_results[doc_id] = parsed_questions\n",
    "        # print(parsed_questions)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for document {doc_id}: {e}\")\n",
    "        # json_questions = json_questions.replace(\"\\n\", \"\\\\n\")\n",
    "        # print(json_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7505b74e-5c87-41a4-ba3a-f3ad98b76ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def clean_json_string(json_string):\n",
    "#     # Remove extra closing brackets if they exist\n",
    "#     json_string = re.sub(r'\\s*\\]\\s*\\]$', ']', json_string)\n",
    "\n",
    "#     # Escape internal double quotes within the strings\n",
    "#     json_string = re.sub(r'(?<!\\\\)\"', r'\\\\\"', json_string)\n",
    "\n",
    "#     # Unescape properly formatted double quotes around the whole JSON\n",
    "#     json_string = re.sub(r'\\\\\\\\\"', r'\"', json_string)\n",
    "    \n",
    "#     return json_string\n",
    "\n",
    "# parsed_results = {}\n",
    "\n",
    "# for doc_id, json_questions in results.items():\n",
    "#     try:\n",
    "#         parsed_questions = json.loads(json_questions)\n",
    "#         parsed_results[doc_id] = parsed_questions\n",
    "#     except json.JSONDecodeError as e:\n",
    "#         print(f\"Error decoding JSON for document {doc_id}: {e}\")\n",
    "#         cleaned_json_questions = clean_json_string(json_questions)\n",
    "#         print(cleaned_json_questions)\n",
    "#         try:\n",
    "#             parsed_questions = json.loads(cleaned_json_questions)\n",
    "#             parsed_results[doc_id] = parsed_questions\n",
    "#         except json.JSONDecodeError as e:\n",
    "#             print(f\"Error decoding cleaned JSON for document {doc_id}: {e}\")\n",
    "#             print(cleaned_json_questions)\n",
    "\n",
    "# # # Print the parsed results\n",
    "# # for doc_id, questions in parsed_results.items():\n",
    "# #     print(f\"Document ID: {doc_id}\")\n",
    "# #     print(f\"Questions: {questions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16701bed-2683-4787-bd46-f55a851bf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# # Function to clean up JSON strings\n",
    "# def clean_json_string(json_string):\n",
    "#     # Remove non-relevant characters and control characters\n",
    "#     json_string = re.sub(r'[\\n\\r\\t]', '', json_string)  # Remove newlines, carriage returns, and tabs\n",
    "#     json_string = re.sub(r'\\\\', '', json_string)  # Remove backslashes\n",
    "#     json_string = re.sub(r'“|”', '\"', json_string)  # Replace fancy quotes with standard quotes\n",
    "#     json_string = re.sub(r'^\\[|\\]$', '', json_string)  # Remove leading and trailing square brackets\n",
    "#     json_string = re.sub(r'^\\{|\\}$', '', json_string)  # Remove leading and trailing curly braces\n",
    "#     return json_string\n",
    "# parsed_results = {}\n",
    "# for doc_id, json_questions in results.items():\n",
    "#     try:\n",
    "        \n",
    "#         parsed_questions = json.loads(json_questions)\n",
    "#         parsed_results[doc_id] = parsed_questions\n",
    "#         print(json_questions)\n",
    "#         # print(parsed_questions)\n",
    "#     except json.JSONDecodeError as e:\n",
    "#         print(f\"Error decoding JSON for document {doc_id}: {e}\")\n",
    "#         # print(json_questions)\n",
    "#         # json_questions = clean_json_string(json_questions)\n",
    "#         # print(json_questions)\n",
    "#         parsed_questions = json.loads(json_questions)\n",
    "#         parsed_results[doc_id] = parsed_questions\n",
    "#         # print(json_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a884aea3-e9b8-47e8-a7f2-087a2d5d5ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parsed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa74de43-c3d2-445f-b998-0e7c079a2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_index = {d['id']: d for d in documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b7459a45-6e45-4acc-bfed-33d8c63f8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6b2af638-e5a2-4846-b089-dfc2805c625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and normalize JSON data\n",
    "def clean_and_normalize_data(data):\n",
    "    if isinstance(data, dict) and 'questions' in data:\n",
    "        return data['questions']\n",
    "    elif isinstance(data, list):\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Process the cleaned data\n",
    "final_results = []\n",
    "\n",
    "for doc_id, questions in parsed_results.items():\n",
    "    group = doc_index.get(doc_id, {}).get('group', 'Unknown')\n",
    "    cleaned_questions = clean_and_normalize_data(questions)\n",
    "    for q in cleaned_questions:\n",
    "        final_results.append((q, group, doc_id))\n",
    "\n",
    "# Print the final results\n",
    "for result in final_results:\n",
    "    # print(result)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dd24d363-65ef-4667-997c-f67074c25064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29e4a76a-e95f-4cf0-b141-bb2254535f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_results, columns=['question', 'Group', 'document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "19f44d5d-7688-40ec-a88e-24474ad9a2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Group</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trong trường hợp môi trường có nhiều mối đe dọ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0ebe745c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tại sao PWO cần phải ưu tiên giải quyết mối đe...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0ebe745c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biện pháp nào được đề xuất để đối phó với tên ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0ebe745c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Việc phát hiện ngư lôi ở cự ly 4.000 yds  tạo ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0ebe745c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Những gì PWO nên làm để đối phó với ngư lôi đa...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0ebe745c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Để hợp tác hiệu quả với nhà tổ chức sự kiện và...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>10833546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Trong quá trình cộng tác, bạn cần thảo luận về...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>10833546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Kế hoạch trước khi tham gia sự kiện, bạn nên l...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>10833546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Bạn có nên phối hợp với các nhiếp ảnh gia và n...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>10833546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Sau sự kiện, bạn nên làm gì để đảm bảo sự hài ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>10833546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question   Group  document\n",
       "0   Trong trường hợp môi trường có nhiều mối đe dọ...  Expert  0ebe745c\n",
       "1   Tại sao PWO cần phải ưu tiên giải quyết mối đe...  Expert  0ebe745c\n",
       "2   Biện pháp nào được đề xuất để đối phó với tên ...  Expert  0ebe745c\n",
       "3   Việc phát hiện ngư lôi ở cự ly 4.000 yds  tạo ...  Expert  0ebe745c\n",
       "4   Những gì PWO nên làm để đối phó với ngư lôi đa...  Expert  0ebe745c\n",
       "..                                                ...     ...       ...\n",
       "80  Để hợp tác hiệu quả với nhà tổ chức sự kiện và...  Expert  10833546\n",
       "81  Trong quá trình cộng tác, bạn cần thảo luận về...  Expert  10833546\n",
       "82  Kế hoạch trước khi tham gia sự kiện, bạn nên l...  Expert  10833546\n",
       "83  Bạn có nên phối hợp với các nhiếp ảnh gia và n...  Expert  10833546\n",
       "84  Sau sự kiện, bạn nên làm gì để đảm bảo sự hài ...  Expert  10833546\n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1173e227-e5f6-4f3a-a7d1-358245b3b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_data/ground_truth204.pkl', 'rb') as file:\n",
    "    results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b0a05acb-00c6-4ff0-a9aa-83295e0098e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON for document 1a090ecc: Expecting ',' delimiter: line 3 column 22 (char 106)\n",
      "Error decoding JSON for document 95a7e364: Expecting ',' delimiter: line 1 column 299 (char 298)\n",
      "Error decoding JSON for document 3ee1a8e5: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for document 913280cb: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "parsed_results = {}\n",
    "for doc_id, json_questions in results.items():\n",
    "    try:\n",
    "        parsed_questions = json.loads(json_questions)\n",
    "        parsed_results[doc_id] = parsed_questions\n",
    "        # print(parsed_questions)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for document {doc_id}: {e}\")\n",
    "        # json_questions = json_questions.replace(\"\\n\", \"\\\\n\")\n",
    "        # print(json_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee9f4af7-d0d4-4757-a767-0566d4682eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and normalize JSON data\n",
    "def clean_and_normalize_data(data):\n",
    "    if isinstance(data, dict) and 'questions' in data:\n",
    "        return data['questions']\n",
    "    elif isinstance(data, list):\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Process the cleaned data\n",
    "final_results = []\n",
    "\n",
    "for doc_id, questions in parsed_results.items():\n",
    "    group = doc_index.get(doc_id, {}).get('group', 'Unknown')\n",
    "    cleaned_questions = clean_and_normalize_data(questions)\n",
    "    for q in cleaned_questions:\n",
    "        final_results.append((q, group, doc_id))\n",
    "\n",
    "# Print the final results\n",
    "for result in final_results:\n",
    "    # print(result)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8456b1b1-7111-4cdd-ae5f-6d039222ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(final_results, columns=['question', 'Group', 'document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a1a3373e-3306-4199-bc49-141a2e1d5b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Group</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kích thước trung bình của một đàn kiến ​​Form...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>1cfe0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Formica rufa thich nghi với những điều kiện mô...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>1cfe0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tại sao không có công thức tính toán kích thướ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>1cfe0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Các yếu tố nào có thể ảnh hưởng đến kích thước...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>1cfe0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ngoài số lượng ong chúa, yếu tố nào khác có th...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>1cfe0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Theo Quy định quốc tế về ngăn ngừa va chạm trê...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>ed2f5cc9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Trong tình huống vượt bến hẹp, tàu nào phải nh...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>ed2f5cc9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Khi tàu bạn ở góc 30 độ trên mũi tàu bên trái ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>ed2f5cc9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Ngành nào sẽ phát ban hành hành động phù hợp k...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>ed2f5cc9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Ngoài việc giảm tốc độ hay chuyển hướng, biện ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>ed2f5cc9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question   Group  document\n",
       "0     kích thước trung bình của một đàn kiến ​​Form...  Expert  1cfe0283\n",
       "1    Formica rufa thich nghi với những điều kiện mô...  Expert  1cfe0283\n",
       "2    Tại sao không có công thức tính toán kích thướ...  Expert  1cfe0283\n",
       "3    Các yếu tố nào có thể ảnh hưởng đến kích thước...  Expert  1cfe0283\n",
       "4    Ngoài số lượng ong chúa, yếu tố nào khác có th...  Expert  1cfe0283\n",
       "..                                                 ...     ...       ...\n",
       "105  Theo Quy định quốc tế về ngăn ngừa va chạm trê...  Expert  ed2f5cc9\n",
       "106  Trong tình huống vượt bến hẹp, tàu nào phải nh...  Expert  ed2f5cc9\n",
       "107  Khi tàu bạn ở góc 30 độ trên mũi tàu bên trái ...  Expert  ed2f5cc9\n",
       "108  Ngành nào sẽ phát ban hành hành động phù hợp k...  Expert  ed2f5cc9\n",
       "109  Ngoài việc giảm tốc độ hay chuyển hướng, biện ...  Expert  ed2f5cc9\n",
       "\n",
       "[110 rows x 3 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b55a4b78-e2cb-473c-a429-4a64138be71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document\n",
       "1cfe0283    5\n",
       "97c28872    5\n",
       "b4f78202    5\n",
       "cbe124b0    5\n",
       "c1e10600    5\n",
       "448bbc4b    5\n",
       "2b8110f8    5\n",
       "a1ec240e    5\n",
       "8ce8ccc0    5\n",
       "3a454b93    5\n",
       "690899f9    5\n",
       "5b72e815    5\n",
       "172b4332    5\n",
       "bad5b7b8    5\n",
       "b331b5fb    5\n",
       "29cb7829    5\n",
       "3e66f963    5\n",
       "d44f62a9    5\n",
       "a06dbd01    5\n",
       "d86f5b4e    5\n",
       "d513d21f    5\n",
       "ed2f5cc9    5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['document'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "827e99a6-c186-43a6-a6c1-c1f44a5abc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "725fbc87-8d6c-48d0-abe7-bc338f4f871a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parsed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f75643e3-7e7f-4606-b3c0-0381a86bb31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ground_truth_file(file_path, doc_index):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        results = pickle.load(file)\n",
    "    \n",
    "    falsed_json_doc_id = []\n",
    "    parsed_results = {}\n",
    "\n",
    "    for doc_id, json_questions in results.items():\n",
    "        try:\n",
    "            parsed_questions = json.loads(json_questions)\n",
    "            parsed_results[doc_id] = parsed_questions\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON for document {doc_id}: {e}\")\n",
    "            falsed_json_doc_id.append(doc_id)\n",
    "            cleaned_json_questions = clean_and_normalize_json_string(json_questions)\n",
    "            try:\n",
    "                parsed_questions = json.loads(cleaned_json_questions)\n",
    "                parsed_results[doc_id] = parsed_questions\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding cleaned JSON for document {doc_id}: {e}\")\n",
    "\n",
    "    final_results = []\n",
    "\n",
    "    for doc_id, questions in parsed_results.items():\n",
    "        group = doc_index.get(doc_id, {}).get('group', 'Unknown')\n",
    "        cleaned_questions = clean_and_normalize_data(questions)\n",
    "        for q in cleaned_questions:\n",
    "            final_results.append((q, group, doc_id))\n",
    "\n",
    "    return final_results, falsed_json_doc_id\n",
    "\n",
    "def process_all_ground_truth_files(directory, doc_index):\n",
    "    all_final_results = []\n",
    "    all_failed_docs = []\n",
    "\n",
    "    for i in range(1, 205):\n",
    "        file_path = os.path.join(directory, f'ground_truth{i}.pkl')\n",
    "        if os.path.exists(file_path):\n",
    "            final_results, failed_docs = process_ground_truth_file(file_path, doc_index)\n",
    "            all_final_results.extend(final_results)\n",
    "            all_failed_docs.extend(failed_docs)\n",
    "        else:\n",
    "            print(f\"File {file_path} does not exist.\")\n",
    "\n",
    "    df = pd.DataFrame(all_final_results, columns=['question', 'Group', 'document'])\n",
    "    return df, all_failed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc0d9c6-3f91-4b74-9a56-b2c562941a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/vietnamese_rag/ground_truth_data'\n",
    "df, failed_docs = process_all_ground_truth_files(directory, doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cf86ec2-e115-4d79-a736-6173bd43825d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Group</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minh Tú đã gặp khó khăn gì trong thử thách đi ...</td>\n",
       "      <td>General</td>\n",
       "      <td>75fafd29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Điểm đến nào là thử thách khó khăn nhất đối vớ...</td>\n",
       "      <td>General</td>\n",
       "      <td>75fafd29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vị trí của Minh Tú trong đêm chung kết Asia's ...</td>\n",
       "      <td>General</td>\n",
       "      <td>75fafd29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Minh Tú đã thể hiện kỹ năng gì khi thực hiện t...</td>\n",
       "      <td>General</td>\n",
       "      <td>75fafd29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Những thử thách nào đã giúp Minh Tú gặt hái th...</td>\n",
       "      <td>General</td>\n",
       "      <td>75fafd29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27825</th>\n",
       "      <td>Theo Quy định quốc tế về ngăn ngừa va chạm trê...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>ed2f5cc9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27826</th>\n",
       "      <td>Trong tình huống vượt bến hẹp, tàu nào phải nh...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>ed2f5cc9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27827</th>\n",
       "      <td>Khi tàu bạn ở góc 30 độ trên mũi tàu bên trái ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>ed2f5cc9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27828</th>\n",
       "      <td>Ngành nào sẽ phát ban hành hành động phù hợp k...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>ed2f5cc9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27829</th>\n",
       "      <td>Ngoài việc giảm tốc độ hay chuyển hướng, biện ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>ed2f5cc9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27830 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question    Group  document\n",
       "0      Minh Tú đã gặp khó khăn gì trong thử thách đi ...  General  75fafd29\n",
       "1      Điểm đến nào là thử thách khó khăn nhất đối vớ...  General  75fafd29\n",
       "2      Vị trí của Minh Tú trong đêm chung kết Asia's ...  General  75fafd29\n",
       "3      Minh Tú đã thể hiện kỹ năng gì khi thực hiện t...  General  75fafd29\n",
       "4      Những thử thách nào đã giúp Minh Tú gặt hái th...  General  75fafd29\n",
       "...                                                  ...      ...       ...\n",
       "27825  Theo Quy định quốc tế về ngăn ngừa va chạm trê...   Expert  ed2f5cc9\n",
       "27826  Trong tình huống vượt bến hẹp, tàu nào phải nh...   Expert  ed2f5cc9\n",
       "27827  Khi tàu bạn ở góc 30 độ trên mũi tàu bên trái ...   Expert  ed2f5cc9\n",
       "27828  Ngành nào sẽ phát ban hành hành động phù hợp k...   Expert  ed2f5cc9\n",
       "27829  Ngoài việc giảm tốc độ hay chuyển hướng, biện ...   Expert  ed2f5cc9\n",
       "\n",
       "[27830 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ba189dc-7515-4638-bc5b-48a16451011e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27830 entries, 0 to 27829\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  27830 non-null  object\n",
      " 1   Group     27830 non-null  object\n",
      " 2   document  27830 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 652.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5de7ce37-59a2-4eef-97c4-307ba03dbdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5c44fc6b-39b5-4f77-901d-84b7603ef342",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents6 = documents.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "53edcf2c-2884-4a4c-a76a-83241851a38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6089"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d1e47bfc-059b-4e52-9ba8-16907e1c3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents7 = []\n",
    "for doc in documents6:\n",
    "    if doc['id'] in failed_docs:\n",
    "        documents7.append(doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "037693df-e380-4a0f-9526-4820a9a8b78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "17cd07dd-e8bb-47ad-b3e6-8497c0278e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_failed_data/documents_failed.json', 'wt') as file:\n",
    "    json.dump(documents7 , file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8a54ff5-18f4-4054-8ad1-dc96fb908cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_failed_data/documents_failed.json', 'rt') as f_in:\n",
    "    documents7 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "411e42f6-9794-4f2f-be70-5ea023299dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 29/29 [00:03<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data/ground_truth_failed1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 29/29 [00:31<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data/ground_truth_failed2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 29/29 [00:41<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data/ground_truth_failed3.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 29/29 [00:28<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data/ground_truth_failed4.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 29/29 [00:40<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data/ground_truth_failed5.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 29/29 [00:35<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 5 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data/ground_truth_failed6.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 29/29 [00:34<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 6 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data/ground_truth_failed7.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 29/29 [00:35<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 7 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data/ground_truth_failed8.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 29/29 [00:31<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data/ground_truth_failed9.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 29/29 [00:34<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 9 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data/ground_truth_failed10.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████▍    | 8/10 [00:01<00:00,  6.71it/s]"
     ]
    }
   ],
   "source": [
    "chunk_size = 29\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents7) // chunk_size)  # Ending chunk index\n",
    "# print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    if (i == end_chunk - 1):\n",
    "        chunk_end = chunk_start + chunk_size + 1\n",
    "    \n",
    "    # print(i + 1, chunk_start, chunk_end)\n",
    "    chunk = documents7[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_failed_data/ground_truth_failed{i + 1}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    # print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2e25e27-75e1-4400-ad05-ee78f55e1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "def clean_and_normalize_json_string(json_string):\n",
    "    # Remove unwanted characters and control characters\n",
    "    json_string = re.sub(r'[\\n\\r\\t]', '', json_string)  # Remove newlines, carriage returns, and tabs\n",
    "    json_string = re.sub(r'\\\\', '', json_string)  # Remove backslashes\n",
    "    json_string = re.sub(r'“|”', '\"', json_string)  # Replace fancy quotes with standard quotes\n",
    "    return json_string\n",
    "def clean_and_normalize_data(data):\n",
    "    if isinstance(data, dict) and 'questions' in data:\n",
    "        return data['questions']\n",
    "    elif isinstance(data, list):\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "def process_ground_truth_file(file_path, doc_index):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        results = pickle.load(file)\n",
    "    \n",
    "    falsed_json_doc_id = []\n",
    "    parsed_results = {}\n",
    "\n",
    "    for doc_id, json_questions in results.items():\n",
    "        try:\n",
    "            parsed_questions = json.loads(json_questions)\n",
    "            parsed_results[doc_id] = parsed_questions\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON for document {doc_id}: {e}\")\n",
    "            falsed_json_doc_id.append(doc_id)\n",
    "            cleaned_json_questions = clean_and_normalize_json_string(json_questions)\n",
    "            try:\n",
    "                parsed_questions = json.loads(cleaned_json_questions)\n",
    "                parsed_results[doc_id] = parsed_questions\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding cleaned JSON for document {doc_id}: {e}\")\n",
    "\n",
    "    final_results = []\n",
    "\n",
    "    for doc_id, questions in parsed_results.items():\n",
    "        group = doc_index.get(doc_id, {}).get('group', 'Unknown')\n",
    "        cleaned_questions = clean_and_normalize_data(questions)\n",
    "        for q in cleaned_questions:\n",
    "            final_results.append((q, group, doc_id))\n",
    "\n",
    "    return final_results, falsed_json_doc_id\n",
    "\n",
    "def process_all_ground_truth_files(directory, doc_index):\n",
    "    all_final_results = []\n",
    "    all_failed_docs = []\n",
    "\n",
    "    for i in range(1, 205):\n",
    "        file_path = os.path.join(directory, f'ground_truth_failed{i}.pkl')\n",
    "        if os.path.exists(file_path):\n",
    "            final_results, failed_docs = process_ground_truth_file(file_path, doc_index)\n",
    "            all_final_results.extend(final_results)\n",
    "            all_failed_docs.extend(failed_docs)\n",
    "        else:\n",
    "            print(f\"File {file_path} does not exist.\")\n",
    "\n",
    "    df = pd.DataFrame(all_final_results, columns=['question', 'Group', 'document'])\n",
    "    return df, all_failed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58d3e6-bb8e-4ae6-b1cc-c577fc0a1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/vietnamese_rag/ground_truth_failed_data'\n",
    "df1, failed_docs = process_all_ground_truth_files(directory, doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15993f4c-7d10-43ec-9010-c1894c4c42ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1225 entries, 0 to 1224\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  1225 non-null   object\n",
      " 1   Group     1225 non-null   object\n",
      " 2   document  1225 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 28.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23da80dd-a931-4f1c-91f8-b3d9346a2722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dea2ba04-e130-461b-82e9-430b1d19381e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Group</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [question, Group, document]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7f56d27-93c8-4c09-88b1-cadde64be46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents8 = documents7.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29ade85b-1d3e-4bd1-8420-e0b47fae8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents9 = []\n",
    "for doc in documents8:\n",
    "    if doc['id'] in failed_docs:\n",
    "        documents9.append(doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cffcb837-da6e-4307-a693-e79808bb4f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_failed_data2/documents_failed.json', 'wt') as file:\n",
    "    json.dump(documents9 , file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19b0e8f6-557e-4790-837e-0d0c1621f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_failed_data2/documents_failed.json', 'rt') as f_in:\n",
    "    documents10 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc5d86d4-899d-4b9b-890b-45aa80ad4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 36\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents10) // chunk_size)  # Ending chunk index\n",
    "# print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    if (i == end_chunk - 1):\n",
    "        chunk_end = chunk_start + chunk_size + 1\n",
    "    \n",
    "    # print(i + 1, chunk_start, chunk_end)\n",
    "    chunk = documents10[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_failed_data2/ground_truth_failed{i + 1}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    # print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "040f0e3a-8dc5-4981-9590-c32ef3acb8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "def clean_and_normalize_json_string(json_string):\n",
    "    # Remove unwanted characters and control characters\n",
    "    json_string = re.sub(r'[\\n\\r\\t]', '', json_string)  # Remove newlines, carriage returns, and tabs\n",
    "    json_string = re.sub(r'\\\\', '', json_string)  # Remove backslashes\n",
    "    json_string = re.sub(r'“|”', '\"', json_string)  # Replace fancy quotes with standard quotes\n",
    "    return json_string\n",
    "def clean_and_normalize_data(data):\n",
    "    if isinstance(data, dict) and 'questions' in data:\n",
    "        return data['questions']\n",
    "    elif isinstance(data, list):\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "def process_ground_truth_file(file_path, doc_index):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        results = pickle.load(file)\n",
    "    \n",
    "    falsed_json_doc_id = []\n",
    "    parsed_results = {}\n",
    "\n",
    "    for doc_id, json_questions in results.items():\n",
    "        try:\n",
    "            parsed_questions = json.loads(json_questions)\n",
    "            parsed_results[doc_id] = parsed_questions\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON for document {doc_id}: {e}\")\n",
    "            falsed_json_doc_id.append(doc_id)\n",
    "            cleaned_json_questions = clean_and_normalize_json_string(json_questions)\n",
    "            try:\n",
    "                parsed_questions = json.loads(cleaned_json_questions)\n",
    "                parsed_results[doc_id] = parsed_questions\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding cleaned JSON for document {doc_id}: {e}\")\n",
    "\n",
    "    final_results = []\n",
    "\n",
    "    for doc_id, questions in parsed_results.items():\n",
    "        group = doc_index.get(doc_id, {}).get('group', 'Unknown')\n",
    "        cleaned_questions = clean_and_normalize_data(questions)\n",
    "        for q in cleaned_questions:\n",
    "            final_results.append((q, group, doc_id))\n",
    "\n",
    "    return final_results, falsed_json_doc_id\n",
    "\n",
    "def process_all_ground_truth_files(directory, doc_index):\n",
    "    all_final_results = []\n",
    "    all_failed_docs = []\n",
    "\n",
    "    for i in range(1, 205):\n",
    "        file_path = os.path.join(directory, f'ground_truth_failed{i}.pkl')\n",
    "        if os.path.exists(file_path):\n",
    "            final_results, failed_docs = process_ground_truth_file(file_path, doc_index)\n",
    "            all_final_results.extend(final_results)\n",
    "            all_failed_docs.extend(failed_docs)\n",
    "        else:\n",
    "            print(f\"File {file_path} does not exist.\")\n",
    "\n",
    "    df = pd.DataFrame(all_final_results, columns=['question', 'Group', 'document'])\n",
    "    return df, all_failed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763c556-5063-4344-a753-6bfdc458c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/vietnamese_rag/ground_truth_failed_data2'\n",
    "df2, failed_docs = process_all_ground_truth_files(directory, doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fdd1a92-7a44-468e-a4ad-3b8ee934e106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115 entries, 0 to 114\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  115 non-null    object\n",
      " 1   Group     115 non-null    object\n",
      " 2   document  115 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e233ba94-1e54-43fa-8e6e-338101f8ab8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd6d1753-65c0-4280-be73-b1a41a6e60b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 10/10 [00:01<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data3/ground_truth_failed1.pkl\n"
     ]
    }
   ],
   "source": [
    "# documents11 = []\n",
    "# for doc in documents10:\n",
    "#     if doc['id'] in failed_docs:\n",
    "#         documents11.append(doc)\n",
    "# with open('../data/vietnamese_rag/ground_truth_failed_data3/documents_failed.json', 'wt') as file:\n",
    "#     json.dump(documents11 , file, indent=2)\n",
    "with open('../data/vietnamese_rag/ground_truth_failed_data3/documents_failed.json', 'rt') as f_in:\n",
    "    documents12 = json.load(f_in)\n",
    "chunk_size = 10\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents12) // chunk_size)  # Ending chunk index\n",
    "# print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    if (i == end_chunk - 1):\n",
    "        chunk_end = chunk_start + chunk_size + 1\n",
    "    \n",
    "    # print(i + 1, chunk_start, chunk_end)\n",
    "    chunk = documents12[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_failed_data3/ground_truth_failed{i + 1}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    # print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f0eac-46f9-41d2-9c7e-bfc838f349c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/vietnamese_rag/ground_truth_failed_data3'\n",
    "df3, failed_docs = process_all_ground_truth_files(directory, doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5edcd3bf-9692-4e13-a068-942f9e7c2d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c3b9651-ee64-4a5e-9373-0ae69c725b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 5/5 [00:00<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 processed and saved to ../data/vietnamese_rag/ground_truth_failed_data4/ground_truth_failed1.pkl\n"
     ]
    }
   ],
   "source": [
    "documents13 = []\n",
    "for doc in documents12:\n",
    "    if doc['id'] in failed_docs:\n",
    "        documents13.append(doc)\n",
    "with open('../data/vietnamese_rag/ground_truth_failed_data4/documents_failed.json', 'wt') as file:\n",
    "    json.dump(documents13 , file, indent=2)\n",
    "with open('../data/vietnamese_rag/ground_truth_failed_data4/documents_failed.json', 'rt') as f_in:\n",
    "    documents14 = json.load(f_in)\n",
    "chunk_size = 5\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents14) // chunk_size)  # Ending chunk index\n",
    "# print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    if (i == end_chunk - 1):\n",
    "        chunk_end = chunk_start + chunk_size + 1\n",
    "    \n",
    "    # print(i + 1, chunk_start, chunk_end)\n",
    "    chunk = documents14[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_failed_data4/ground_truth_failed{i + 1}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    # print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53055a1d-5f23-4452-8714-03b5b506d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/vietnamese_rag/ground_truth_failed_data4'\n",
    "df4, failed_docs = process_all_ground_truth_files(directory, doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "117e1e86-e61e-4f01-87d0-69cd19963682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33538dc0-a0b7-40a2-b04b-ee04ae943963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  25 non-null     object\n",
      " 1   Group     25 non-null     object\n",
      " 2   document  25 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 728.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7cb7985-1306-4a69-856f-af5e9eb44b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df, df1, df2, df3, and df4 are your DataFrames\n",
    "ground_truth_data = pd.concat([df, df1, df2, df3, df4], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "262924a2-aaae-4b9f-bdfd-185184258439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29215 entries, 0 to 29214\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  29215 non-null  object\n",
      " 1   Group     29215 non-null  object\n",
      " 2   document  29215 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 684.9+ KB\n"
     ]
    }
   ],
   "source": [
    "ground_truth_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b9f0883-34b7-4d0a-99cf-5825eb71c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_data.to_csv('../data/vietnamese_rag/ground_truth_data/ground_truth_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "025ce6e9-4322-46bf-ac27-ccb2f241a196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29215 entries, 0 to 29214\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  29215 non-null  object\n",
      " 1   Group     29215 non-null  object\n",
      " 2   document  29215 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 684.9+ KB\n"
     ]
    }
   ],
   "source": [
    "ground_truth_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80a7b7f8-239b-49ea-8db9-8b2c93e9fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = ground_truth_data['question'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79834b48-9b08-499e-ba7c-b328bb44e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in question_list[:5]:\n",
    "    if (len(q) <= 5):\n",
    "        print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "190ee323-5120-444e-b02c-595b5bf95a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0a639f21',\n",
       " '0c97c2ce',\n",
       " '1924dfc8',\n",
       " '35ff10f5',\n",
       " '471f7c77',\n",
       " '5abb105e',\n",
       " '7c0879dc',\n",
       " '7d3646ff',\n",
       " '8b79ef4e',\n",
       " 'bc1b226c',\n",
       " 'cac38a18',\n",
       " 'e3039526',\n",
       " 'f6c157cd'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list = ['cac38a18',\n",
    " 'cac38a18',\n",
    " '1924dfc8',\n",
    " 'f6c157cd',\n",
    " '35ff10f5',\n",
    " '35ff10f5',\n",
    " '35ff10f5',\n",
    " '35ff10f5',\n",
    " '35ff10f5',\n",
    " '0c97c2ce',\n",
    " 'e3039526',\n",
    " 'e3039526',\n",
    " 'e3039526',\n",
    " 'e3039526',\n",
    " '471f7c77',\n",
    " '7c0879dc',\n",
    " '7c0879dc',\n",
    " '7c0879dc',\n",
    " '7c0879dc',\n",
    " '8b79ef4e',\n",
    " 'bc1b226c',\n",
    " '5abb105e',\n",
    " '5abb105e',\n",
    " '5abb105e',\n",
    " '5abb105e',\n",
    " '7d3646ff',\n",
    " '7d3646ff',\n",
    " '0a639f21']\n",
    "id_set = set(id_list)\n",
    "id_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2fb6f435-3839-4306-ac81-8a7bd4841d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Group</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td></td>\n",
       "      <td>General</td>\n",
       "      <td>cac38a18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td></td>\n",
       "      <td>General</td>\n",
       "      <td>cac38a18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>Đến tháng 7 năm 2017, Facebook có bao nhiêu ng...</td>\n",
       "      <td>General</td>\n",
       "      <td>cac38a18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>Vào tháng 7 năm 2017, số người sử dụng Faceboo...</td>\n",
       "      <td>General</td>\n",
       "      <td>cac38a18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>Tại Việt Nam, vào tháng 7 năm 2017, có bao nhi...</td>\n",
       "      <td>General</td>\n",
       "      <td>cac38a18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29195</th>\n",
       "      <td>Để tránh hiệu ứng lô hay lứa trong thí nghiệm,...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0a639f21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29196</th>\n",
       "      <td>Mỗi đợt nhân giống có bao nhiêu con chuột có t...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0a639f21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29197</th>\n",
       "      <td>Có bao nhiêu nhóm thí nghiệm trong thí nghiệm ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0a639f21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29198</th>\n",
       "      <td>Vì sao việc phân ngẫu nhiên chuột quan trọng t...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0a639f21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29199</th>\n",
       "      <td>Khi nào sẽ đạt được tổng số 20 con chuột trong...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0a639f21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question    Group  document\n",
       "2021                                                      General  cac38a18\n",
       "2022                                                      General  cac38a18\n",
       "2023   Đến tháng 7 năm 2017, Facebook có bao nhiêu ng...  General  cac38a18\n",
       "2024   Vào tháng 7 năm 2017, số người sử dụng Faceboo...  General  cac38a18\n",
       "2025   Tại Việt Nam, vào tháng 7 năm 2017, có bao nhi...  General  cac38a18\n",
       "...                                                  ...      ...       ...\n",
       "29195  Để tránh hiệu ứng lô hay lứa trong thí nghiệm,...   Expert  0a639f21\n",
       "29196  Mỗi đợt nhân giống có bao nhiêu con chuột có t...   Expert  0a639f21\n",
       "29197  Có bao nhiêu nhóm thí nghiệm trong thí nghiệm ...   Expert  0a639f21\n",
       "29198  Vì sao việc phân ngẫu nhiên chuột quan trọng t...   Expert  0a639f21\n",
       "29199  Khi nào sẽ đạt được tổng số 20 con chuột trong...   Expert  0a639f21\n",
       "\n",
       "[82 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_data[ground_truth_data['document'].isin(id_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a94ce0a-77b4-4966-8ea7-6a8282a06647",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = []\n",
    "for id in id_set:\n",
    "    question_list.append(ground_truth_data[ground_truth_data['document'] == id]['question'].tolist())\n",
    "    # print(ground_truth_data[ground_truth_data['document'] == id]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25a51e5f-9494-4bc4-b403-e3222c930b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Cước phí viễn thông trả sau bị phạt bao nhiêu nếu người dùng thực hiện hòa mạng trước thời hạn?', 'Hình phạt nào áp dụng khi khách hàng ngưng sử dụng dịch vụ trước khi hoàn tất hợp đồng?', 'Hòa mạng trước khi thanh toán tiền sử dụng dịch vụ, mức phạt là bao nhiêu?', 'Thực hiện hòa mạng trước khi ký kết hợp đồng, người dùng sẽ bị phạt bao nhiêu tiền?']\n",
      "['', '', 'Một số phương pháp cai nghiện nào được sử dụng để hỗ trợ người nghiện rượu?', 'Công nghệ hiện đại trong cai nghiện rượu là gì?', 'Những hiểu biết mới trong chuyển hóa rượu có thể dẫn đến những biện pháp can thiệp gì?', 'Trung tâm cai nghiện cung cấp những dịch vụ gì cho người nghiện rượu?']\n",
      "['', '¿Cuándo se restableció el servicio de compensación y pago de operaciones de derivados del mercado de valores?', '', '', '']\n",
      "['', '', '', '', ' ']\n",
      "['Lãi suất cho giấy tờ có giá được áp dụng như thế nào?', 'Ngân hàng Nhà nước quy định lãi suất cho giấy tờ có giá theo cách nào?', 'Phương thức tính lãi suất đối với giấy tờ có giá là gì?', 'Nguyên tắc chung trong việc xác định lãi suất cho giấy tờ có giá là gì?', 'Liệu lãi suất cho giấy tờ có giá có thay đổi theo thời gian?', '', 'Lãi suất đối với giấy tờ có giá được điều chỉnh như thế nào?', 'Ngân hàng Nhà nước Việt Nam quy định gì về lãi suất cho giấy tờ có giá?', 'Phương pháp tính lãi suất cho giấy tờ có giá là như thế nào?', 'Có sự thay đổi về lãi suất cho giấy tờ có giá theo thời gian không?', 'Ai quyết định lãi suất đối với giấy tờ có giá?']\n",
      "['Làm thế nào để phân bổ chuột cho thí nghiệm khi số lượng con chuột có sẵn hạn chế? ', '', 'Loại thiết kế phân nhóm nào tốt nhất để tránh hiệu ứng lô trong thí nghiệm trên động vật?', 'Tại sao việc phân ngẫu nhiên chuột quan trọng trong thí nghiệm?', 'Bạn có thể mô tả chi tiết hơn về cách thực hiện thiết kế khối ngẫu nhiên cho thí nghiệm động vật?', 'Để tránh hiệu ứng lô hay lứa trong thí nghiệm, người ta nên phân phối chuột như thế nào?', 'Mỗi đợt nhân giống có bao nhiêu con chuột có thể sử dụng được?', 'Có bao nhiêu nhóm thí nghiệm trong thí nghiệm này?', 'Vì sao việc phân ngẫu nhiên chuột quan trọng trong thiết kế thí nghiệm?', 'Khi nào sẽ đạt được tổng số 20 con chuột trong mỗi nhóm thí nghiệm?']\n",
      "['', {'question': 'Điều kiện cụ thể để trở thành bảo vệ ở Việt Nam là gì?', 'answer': 'Công dân Việt Nam đủ 18 tuổi trở lên có thể làm bảo vệ, nếu họ đáp ứng đủ các điều kiện khác được yêu cầu.'}, {'question': 'Độ tuổi tối thiểu để làm bảo vệ ở Việt Nam là bao nhiêu?', 'answer': 'Công dân Việt Nam đủ 18 tuổi trở lên có thể làm bảo vệ.'}, {'question': 'Có hạn chế về độ tuổi để làm bảo vệ ở Việt Nam không?', 'answer': \"Không có thông tin chi tiết về việc định nghĩa 'người cao tuổi' trong trường hợp này.\"}, {'question': 'Ngoài độ tuổi, điều kiện gì khác để làm bảo vệ?', 'answer': 'Công dân Việt Nam đủ 18 tuổi trở lên có thể làm bảo vệ, nếu họ đáp ứng đủ các điều kiện khác được yêu cầu.'}, {'question': 'Từ 18 tuổi trở lên có thể làm bảo vệ được không?', 'answer': 'Công dân Việt Nam đủ 18 tuổi trở lên có thể làm bảo vệ, nếu họ đáp ứng đủ các điều kiện khác được yêu cầu.'}]\n",
      "['', '', '', '', '']\n",
      "['', '', 'Đến tháng 7 năm 2017, Facebook có bao nhiêu người dùng ở Việt Nam?', 'Vào tháng 7 năm 2017, số người sử dụng Facebook ở Việt Nam tính bao nhiêu???', 'Tại Việt Nam, vào tháng 7 năm 2017, có bao nhiêu người dùng Facebook?', 'Theo thống kê tháng 7 năm 2017, số lượng người dùng Facebook tại Việt Nam là bao nhiêu?']\n",
      "['', 'Những trường hợp nào cần phải chỉnh lý và bổ sung số liệu trong báo cáo thống kê ngành tư pháp?', 'Báo cáo thống kê ngành tư pháp chỉnh lý như thế nào?', 'Thời gian lập báo cáo thống kê ngành tư pháp được ghi như thế nào?', 'Việc xác nhận báo cáo thống kê ngành tư pháp được thực hiện bằng phương thức nào?']\n",
      "['', ' Mức phạt cho hành vi chiếm dụng dải phân cách giữa hai làn đường là bao nhiêu?', 'Khi sử dụng dải phân cách giữa đường đôi để xe, trông, giữ xe, cá nhân sẽ bị phạt bao nhiêu tiền?', 'Có sự khác biệt về mức phạt đối với cá nhân và tổ chức khi chiếm dụng dải phân cách giữa đường?', 'Bạn có thể cho tôi biết số tiền tối đa một cá nhân phải đóng khi vi phạm luật về chiếm dụng dải phân cách?', 'Tổ chức sẽ bị phạt tối đa bao nhiêu tiền nếu vi phạm luật về chiếm dụng dải phân cách?']\n",
      "['', ' ', 'Thời gian làm nhiệm vụ của thẩm phán lần đầu tiên là bao lâu?', 'Nếu được bổ nhiệm lại hay chuyển sang ngạch thẩm phán khác, nhiệm kỳ tiếp theo của thẩm phán kéo dài bao nhiêu năm?', 'Thẩm phán có thể được bổ nhiệm lại không?', 'Ngành nghề của thẩm phán là gì?']\n",
      "['', '', '', 'Các chất hoạt động bề mặt nào giúp cải thiện khả năng tương thích sinh học của các hạt nano từ tính?', '', 'Ứng dụng nào của các hạt nano từ tính được đề cập trong câu trả lời?']\n"
     ]
    }
   ],
   "source": [
    "for list in question_list:\n",
    "    for question in list:\n",
    "        if (len(question) == 0):\n",
    "            print(list)\n",
    "            break\n",
    "    # print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37b2e954-ee20-4325-89a2-020f4d00567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ground_truth_data['document'].isin(id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee16d2bf-24cb-4df7-91ab-80d49763d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = ground_truth_data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "34ddad16-a5fa-4700-9345-81f6ae061394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29133 entries, 0 to 29214\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  29133 non-null  object\n",
      " 1   Group     29133 non-null  object\n",
      " 2   document  29133 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 910.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "30f91c35-b11c-4215-ab2c-1cb45016276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_documents = []\n",
    "for doc in documents:\n",
    "    if doc['id'] in id_set:\n",
    "        missing_documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f34d3d0a-31de-40c1-8b0b-41f4e63bbb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/ground_truth_missing_questions/documents_missing.json', 'wt') as file:\n",
    "    json.dump(missing_documents , file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f979230b-1565-4f91-8753-4f9edb7e8206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2d37b-1cd5-4fa1-a753-16f98a73ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "56158a86-5950-4021-be0a-61eece4a6f64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 13/13 [00:01<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 processed and saved to ../data/vietnamese_rag/ground_truth_missing_questions/ground_truth_missing1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████| 2/2 [00:01<00:00,  1.94it/s]"
     ]
    }
   ],
   "source": [
    "chunk_size = 13\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(missing_documents) // chunk_size)  # Ending chunk index\n",
    "# print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    if (i == end_chunk - 1):\n",
    "        chunk_end = chunk_start + chunk_size + 1\n",
    "    \n",
    "    # print(i + 1, chunk_start, chunk_end)\n",
    "    chunk = missing_documents[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_missing_questions/ground_truth_missing{i + 1}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    # print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    # time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b2cc09ef-0e0b-4827-ad29-04c3811f6332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON for document bc1b226c: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding cleaned JSON for document bc1b226c: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for document 7d3646ff: Invalid control character at: line 3 column 3 (char 173)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def clean_and_normalize_json_string(json_string):\n",
    "    # Remove unwanted characters and control characters\n",
    "    json_string = re.sub(r'[\\n\\r\\t]', '', json_string)  # Remove newlines, carriage returns, and tabs\n",
    "    json_string = re.sub(r'\\\\', '', json_string)  # Remove backslashes\n",
    "    json_string = re.sub(r'“|”', '\"', json_string)  # Replace fancy quotes with standard quotes\n",
    "    return json_string\n",
    "\n",
    "def clean_and_normalize_data(data):\n",
    "    # print(data)\n",
    "    if isinstance(data, dict) and 'questions' in data:\n",
    "        return data['questions']\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def process_ground_truth_file(file_path, doc_index):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        results = pickle.load(file)\n",
    "    \n",
    "    falsed_json_doc_id = []\n",
    "    parsed_results = {}\n",
    "\n",
    "    for doc_id, json_questions in results.items():\n",
    "        try:\n",
    "            parsed_questions = json.loads(json_questions)\n",
    "            parsed_results[doc_id] = parsed_questions\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON for document {doc_id}: {e}\")\n",
    "            falsed_json_doc_id.append(doc_id)\n",
    "            cleaned_json_questions = clean_and_normalize_json_string(json_questions)\n",
    "            try:\n",
    "                parsed_questions = json.loads(cleaned_json_questions)\n",
    "                parsed_results[doc_id] = parsed_questions\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding cleaned JSON for document {doc_id}: {e}\")\n",
    "\n",
    "    final_results = []\n",
    "\n",
    "    for doc_id, questions in parsed_results.items():\n",
    "        group = doc_index.get(doc_id, {}).get('group', 'Unknown')\n",
    "        cleaned_questions = clean_and_normalize_data(questions)\n",
    "        for q in cleaned_questions:\n",
    "            final_results.append((q, group, doc_id))\n",
    "\n",
    "    return final_results, falsed_json_doc_id\n",
    "\n",
    "def process_all_ground_truth_files(directory, doc_index):\n",
    "    all_final_results = []\n",
    "    all_failed_docs = []\n",
    "\n",
    "    for i in range(1, 2):\n",
    "        file_path = os.path.join(directory, f'ground_truth_missing{i}.pkl')\n",
    "        if os.path.exists(file_path):\n",
    "            final_results, failed_docs = process_ground_truth_file(file_path, doc_index)\n",
    "            all_final_results.extend(final_results)\n",
    "            all_failed_docs.extend(failed_docs)\n",
    "        else:\n",
    "            print(f\"File {file_path} does not exist.\")\n",
    "\n",
    "    df = pd.DataFrame(all_final_results, columns=['question', 'Group', 'document'])\n",
    "    return df, all_failed_docs\n",
    "\n",
    "# Example usage\n",
    "directory = '../data/vietnamese_rag/ground_truth_missing_questions'\n",
    "df5, failed_docs = process_all_ground_truth_files(directory, doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9572bf3b-b257-4b09-93e4-28f14ad6b60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3b57ddeb-bb90-4a70-8bae-73b844b33025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 2/2 [00:01<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 processed and saved to ../data/vietnamese_rag/ground_truth_missing_questions/ground_truth_missing2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "missing_documents2 = []\n",
    "for doc in documents:\n",
    "    if doc['id'] in failed_docs:\n",
    "        missing_documents2.append(doc)\n",
    "with open('../data/vietnamese_rag/ground_truth_missing_questions/documents_missing2.json', 'wt') as file:\n",
    "    json.dump(missing_documents2 , file, indent=2)\n",
    "chunk_size = 2\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(missing_documents2) // chunk_size)  # Ending chunk index\n",
    "# print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    if (i == end_chunk - 1):\n",
    "        chunk_end = chunk_start + chunk_size + 1\n",
    "    \n",
    "    # print(i + 1, chunk_start, chunk_end)\n",
    "    chunk = missing_documents2[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_missing_questions/ground_truth_missing{i + 2}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    # print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    # time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e4520382-5de5-4b43-b227-597e60fc5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def clean_and_normalize_json_string(json_string):\n",
    "    # Remove unwanted characters and control characters\n",
    "    json_string = re.sub(r'[\\n\\r\\t]', '', json_string)  # Remove newlines, carriage returns, and tabs\n",
    "    json_string = re.sub(r'\\\\', '', json_string)  # Remove backslashes\n",
    "    json_string = re.sub(r'“|”', '\"', json_string)  # Replace fancy quotes with standard quotes\n",
    "    return json_string\n",
    "\n",
    "def clean_and_normalize_data(data):\n",
    "    # print(data)\n",
    "    if isinstance(data, dict) and 'questions' in data:\n",
    "        return data['questions']\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def process_ground_truth_file(file_path, doc_index):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        results = pickle.load(file)\n",
    "    \n",
    "    falsed_json_doc_id = []\n",
    "    parsed_results = {}\n",
    "\n",
    "    for doc_id, json_questions in results.items():\n",
    "        try:\n",
    "            parsed_questions = json.loads(json_questions)\n",
    "            parsed_results[doc_id] = parsed_questions\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON for document {doc_id}: {e}\")\n",
    "            falsed_json_doc_id.append(doc_id)\n",
    "            cleaned_json_questions = clean_and_normalize_json_string(json_questions)\n",
    "            try:\n",
    "                parsed_questions = json.loads(cleaned_json_questions)\n",
    "                parsed_results[doc_id] = parsed_questions\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding cleaned JSON for document {doc_id}: {e}\")\n",
    "\n",
    "    final_results = []\n",
    "\n",
    "    for doc_id, questions in parsed_results.items():\n",
    "        group = doc_index.get(doc_id, {}).get('group', 'Unknown')\n",
    "        cleaned_questions = clean_and_normalize_data(questions)\n",
    "        for q in cleaned_questions:\n",
    "            final_results.append((q, group, doc_id))\n",
    "\n",
    "    return final_results, falsed_json_doc_id\n",
    "\n",
    "def process_all_ground_truth_files(directory, doc_index):\n",
    "    all_final_results = []\n",
    "    all_failed_docs = []\n",
    "\n",
    "    for i in range(2, 3):\n",
    "        file_path = os.path.join(directory, f'ground_truth_missing{i}.pkl')\n",
    "        if os.path.exists(file_path):\n",
    "            final_results, failed_docs = process_ground_truth_file(file_path, doc_index)\n",
    "            all_final_results.extend(final_results)\n",
    "            all_failed_docs.extend(failed_docs)\n",
    "        else:\n",
    "            print(f\"File {file_path} does not exist.\")\n",
    "\n",
    "    df = pd.DataFrame(all_final_results, columns=['question', 'Group', 'document'])\n",
    "    return df, all_failed_docs\n",
    "# Example usage\n",
    "directory = '../data/vietnamese_rag/ground_truth_missing_questions'\n",
    "df6, failed_docs = process_all_ground_truth_files(directory, doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5d1bd703-4427-4ca4-a532-5c0bd13a0ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "92128c97-d6b6-49f6-a2b5-8ddc1e16d5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Group</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vào tháng 7 năm 2017, số người dùng Facebook ở...</td>\n",
       "      <td>General</td>\n",
       "      <td>cac38a18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Số người Việt Nam được ước tính sử dụng Facebo...</td>\n",
       "      <td>General</td>\n",
       "      <td>cac38a18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook có bao nhiêu người dùng tại Việt Nam ...</td>\n",
       "      <td>General</td>\n",
       "      <td>cac38a18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ở Việt Nam, tháng 7 năm 2017 có bao nhiêu ngườ...</td>\n",
       "      <td>General</td>\n",
       "      <td>cac38a18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lượng người dùng Facebook tại Việt Nam vào thá...</td>\n",
       "      <td>General</td>\n",
       "      <td>cac38a18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nhiệm kỳ ban đầu của một thẩm phán là bao nhiêu?</td>\n",
       "      <td>Legal</td>\n",
       "      <td>1924dfc8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Làm thế nào một thẩm phán có thể được bổ nhiệm...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>1924dfc8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Độ dài nhiệm kỳ của thẩm phán sau khi được bổ ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>1924dfc8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Họ sẽ được bổ nhiệm lại vào vị trí cũ hay vị t...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>1924dfc8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Có sự thay đổi về nhiệm kỳ giữa thẩm phán mới ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>1924dfc8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Để làm bảo vệ, công dân Việt Nam phải đủ tuổi ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>f6c157cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ngoài tuổi, có điều kiện gì khác để làm bảo vệ?</td>\n",
       "      <td>Legal</td>\n",
       "      <td>f6c157cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bản ghi không đề cập đến việc định nghĩa 'ngườ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>f6c157cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ai có thể làm bảo vệ theo luật pháp Việt Nam?</td>\n",
       "      <td>Legal</td>\n",
       "      <td>f6c157cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Có thể tìm hiểu thêm thông tin về tuổi làm bảo...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>f6c157cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Theo quy định nào thì có thể lập danh mục rà s...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>35ff10f5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ai có thẩm quyền chỉ đạo việc lập danh mục rà ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>35ff10f5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bên cạnh chỉ đạo, có yếu tố nào khác ảnh hưởng...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>35ff10f5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cơ quan nào có quyền quyết định việc lập danh ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>35ff10f5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lựa chọn TTHC nào để được rà soát, đánh giá tr...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>35ff10f5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Người vay giấy tờ có giá được tính lãi theo ph...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>0c97c2ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ngân hàng Nhà nước Việt Nam quy định lãi suất ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>0c97c2ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lãi suất giấy tờ có giá thay đổi như thế nào t...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>0c97c2ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lãi suất giấy tờ có giá có bị điều chỉnh thườn...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>0c97c2ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Có những cơ quan nào quản lý lãi suất giấy tờ ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>0c97c2ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Khi nào tổ chức cung cấp dịch vụ bù trừ, thanh...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>e3039526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Điều kiện để tổ chức cung cấp dịch vụ bù trừ, ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>e3039526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Vì sao tổ chức cung cấp dịch vụ bù trừ, thanh ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>e3039526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Những hành vi nào dẫn tới đình chỉ hoạt động c...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>e3039526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Khi tổ chức cung cấp dịch vụ bù trừ, thanh toá...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>e3039526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Trường hợp nào vi phạm khi thực hiện hòa mạng ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>471f7c77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Hòa mạng trước khi ký hợp đồng có bị phạt tiền...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>471f7c77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Hình phạt khi hòa mạng trước khi thanh toán ti...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>471f7c77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Giới hạn mức phạt tiền cho việc hòa mạng trước...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>471f7c77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Tín hiệu vi phạm khi hòa mạng trước khi người ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>471f7c77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Theo quy định của pháp luật, ai có trách nhiệm...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>7c0879dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Những ai phải tuân thủ quy định về bảo vệ bí m...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>7c0879dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Phạm vi quản lý thông tin, dữ liệu, sản phẩm đ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>7c0879dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Quy định pháp luật nào quy định việc bảo mật t...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>7c0879dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bảo mật thông tin, dữ liệu, sản phẩm đo đạc và...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>7c0879dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Tử số phạt cho cá nhân vi phạm chiếm dụng dải ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>8b79ef4e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Phạt bao nhiêu tiền nếu tổ chức chiếm dụng dải...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>8b79ef4e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Có phạt xe máy, xe ô tô hay cả, khi chiếm dụng...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>8b79ef4e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Người vi phạm chiếm dụng dải phân cách giữa đư...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>8b79ef4e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mức phạt tối đa là bao nhiêu đối với cá nhân v...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>8b79ef4e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Những chất hoạt động bề mặt nào được sử dụng đ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>5abb105e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ngoài CTAB, chất hoạt động bề mặt cation nào k...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>5abb105e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Chất hoạt động bề mặt không ion nào thường đượ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>5abb105e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Lợi ích của việc phủ hạt nano từ tính bằng chấ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>5abb105e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Các ứng dụng sinh học nào sử dụng hạt nano từ ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>5abb105e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Có những phương pháp nào được sử dụng để giúp ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>7d3646ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Trung tâm cai nghiện cung cấp những dịch vụ gì...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>7d3646ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Kỹ thuật thay đổi hành vi trong điều trị nghiệ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>7d3646ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Công nghệ cảm biến rượu có tác dụng gì trong v...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>7d3646ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Những hiểu biết mới về rượu đã góp phần phát t...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>7d3646ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Trong thí nghiệm với động vật có số lượng hạn ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0a639f21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Thí nghiệm của tôi cần 20 con chuột trong mỗi ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0a639f21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Giải thích rõ hơn về thiết kế khối ngẫu nhiên ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0a639f21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Thiết kế khối ngẫu nhiên như thế nào giúp đảm ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0a639f21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Bằng cách phân ngẫu nhiên chuột từ mỗi lứa vào...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>0a639f21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question    Group  document\n",
       "0   Vào tháng 7 năm 2017, số người dùng Facebook ở...  General  cac38a18\n",
       "1   Số người Việt Nam được ước tính sử dụng Facebo...  General  cac38a18\n",
       "2   Facebook có bao nhiêu người dùng tại Việt Nam ...  General  cac38a18\n",
       "3   Ở Việt Nam, tháng 7 năm 2017 có bao nhiêu ngườ...  General  cac38a18\n",
       "4   Lượng người dùng Facebook tại Việt Nam vào thá...  General  cac38a18\n",
       "5    Nhiệm kỳ ban đầu của một thẩm phán là bao nhiêu?    Legal  1924dfc8\n",
       "6   Làm thế nào một thẩm phán có thể được bổ nhiệm...    Legal  1924dfc8\n",
       "7   Độ dài nhiệm kỳ của thẩm phán sau khi được bổ ...    Legal  1924dfc8\n",
       "8   Họ sẽ được bổ nhiệm lại vào vị trí cũ hay vị t...    Legal  1924dfc8\n",
       "9   Có sự thay đổi về nhiệm kỳ giữa thẩm phán mới ...    Legal  1924dfc8\n",
       "10  Để làm bảo vệ, công dân Việt Nam phải đủ tuổi ...    Legal  f6c157cd\n",
       "11    Ngoài tuổi, có điều kiện gì khác để làm bảo vệ?    Legal  f6c157cd\n",
       "12  Bản ghi không đề cập đến việc định nghĩa 'ngườ...    Legal  f6c157cd\n",
       "13      Ai có thể làm bảo vệ theo luật pháp Việt Nam?    Legal  f6c157cd\n",
       "14  Có thể tìm hiểu thêm thông tin về tuổi làm bảo...    Legal  f6c157cd\n",
       "15  Theo quy định nào thì có thể lập danh mục rà s...    Legal  35ff10f5\n",
       "16  Ai có thẩm quyền chỉ đạo việc lập danh mục rà ...    Legal  35ff10f5\n",
       "17  Bên cạnh chỉ đạo, có yếu tố nào khác ảnh hưởng...    Legal  35ff10f5\n",
       "18  Cơ quan nào có quyền quyết định việc lập danh ...    Legal  35ff10f5\n",
       "19  Lựa chọn TTHC nào để được rà soát, đánh giá tr...    Legal  35ff10f5\n",
       "20  Người vay giấy tờ có giá được tính lãi theo ph...    Legal  0c97c2ce\n",
       "21  Ngân hàng Nhà nước Việt Nam quy định lãi suất ...    Legal  0c97c2ce\n",
       "22  Lãi suất giấy tờ có giá thay đổi như thế nào t...    Legal  0c97c2ce\n",
       "23  Lãi suất giấy tờ có giá có bị điều chỉnh thườn...    Legal  0c97c2ce\n",
       "24  Có những cơ quan nào quản lý lãi suất giấy tờ ...    Legal  0c97c2ce\n",
       "25  Khi nào tổ chức cung cấp dịch vụ bù trừ, thanh...    Legal  e3039526\n",
       "26  Điều kiện để tổ chức cung cấp dịch vụ bù trừ, ...    Legal  e3039526\n",
       "27  Vì sao tổ chức cung cấp dịch vụ bù trừ, thanh ...    Legal  e3039526\n",
       "28  Những hành vi nào dẫn tới đình chỉ hoạt động c...    Legal  e3039526\n",
       "29  Khi tổ chức cung cấp dịch vụ bù trừ, thanh toá...    Legal  e3039526\n",
       "30  Trường hợp nào vi phạm khi thực hiện hòa mạng ...    Legal  471f7c77\n",
       "31  Hòa mạng trước khi ký hợp đồng có bị phạt tiền...    Legal  471f7c77\n",
       "32  Hình phạt khi hòa mạng trước khi thanh toán ti...    Legal  471f7c77\n",
       "33  Giới hạn mức phạt tiền cho việc hòa mạng trước...    Legal  471f7c77\n",
       "34  Tín hiệu vi phạm khi hòa mạng trước khi người ...    Legal  471f7c77\n",
       "35  Theo quy định của pháp luật, ai có trách nhiệm...    Legal  7c0879dc\n",
       "36  Những ai phải tuân thủ quy định về bảo vệ bí m...    Legal  7c0879dc\n",
       "37  Phạm vi quản lý thông tin, dữ liệu, sản phẩm đ...    Legal  7c0879dc\n",
       "38  Quy định pháp luật nào quy định việc bảo mật t...    Legal  7c0879dc\n",
       "39  Bảo mật thông tin, dữ liệu, sản phẩm đo đạc và...    Legal  7c0879dc\n",
       "40  Tử số phạt cho cá nhân vi phạm chiếm dụng dải ...    Legal  8b79ef4e\n",
       "41  Phạt bao nhiêu tiền nếu tổ chức chiếm dụng dải...    Legal  8b79ef4e\n",
       "42  Có phạt xe máy, xe ô tô hay cả, khi chiếm dụng...    Legal  8b79ef4e\n",
       "43  Người vi phạm chiếm dụng dải phân cách giữa đư...    Legal  8b79ef4e\n",
       "44  Mức phạt tối đa là bao nhiêu đối với cá nhân v...    Legal  8b79ef4e\n",
       "45  Những chất hoạt động bề mặt nào được sử dụng đ...   Expert  5abb105e\n",
       "46  Ngoài CTAB, chất hoạt động bề mặt cation nào k...   Expert  5abb105e\n",
       "47  Chất hoạt động bề mặt không ion nào thường đượ...   Expert  5abb105e\n",
       "48  Lợi ích của việc phủ hạt nano từ tính bằng chấ...   Expert  5abb105e\n",
       "49  Các ứng dụng sinh học nào sử dụng hạt nano từ ...   Expert  5abb105e\n",
       "50  Có những phương pháp nào được sử dụng để giúp ...   Expert  7d3646ff\n",
       "51  Trung tâm cai nghiện cung cấp những dịch vụ gì...   Expert  7d3646ff\n",
       "52  Kỹ thuật thay đổi hành vi trong điều trị nghiệ...   Expert  7d3646ff\n",
       "53  Công nghệ cảm biến rượu có tác dụng gì trong v...   Expert  7d3646ff\n",
       "54  Những hiểu biết mới về rượu đã góp phần phát t...   Expert  7d3646ff\n",
       "55  Trong thí nghiệm với động vật có số lượng hạn ...   Expert  0a639f21\n",
       "56  Thí nghiệm của tôi cần 20 con chuột trong mỗi ...   Expert  0a639f21\n",
       "57  Giải thích rõ hơn về thiết kế khối ngẫu nhiên ...   Expert  0a639f21\n",
       "58  Thiết kế khối ngẫu nhiên như thế nào giúp đảm ...   Expert  0a639f21\n",
       "59  Bằng cách phân ngẫu nhiên chuột từ mỗi lứa vào...   Expert  0a639f21"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "40c4a6b6-a0ea-461c-83cc-4be0fefcd85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Group</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cần làm gì khi số liệu thống kê ngành tư pháp ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>bc1b226c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hình thức nào để bổ sung số liệu trong báo cáo...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>bc1b226c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thông tin gì cần ghi trong văn bản báo cáo thố...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>bc1b226c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ngoài văn bản, có cách nào khác để bổ sung số ...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>bc1b226c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Báo cáo thống kê ngành tư pháp được xác nhận b...</td>\n",
       "      <td>Legal</td>\n",
       "      <td>bc1b226c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Các trung tâm cai nghiện rượu hiện nay cung cấ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>7d3646ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kỹ thuật thay đổi hành vi trong việc cai nghiệ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>7d3646ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Công nghệ cảm biến rượu có tác dụng gì trong đ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>7d3646ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Những hiểu biết mới về chuyển hóa rượu có thể ...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>7d3646ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Triệu chứng cai nghiện rượu có thể được ngăn n...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>7d3646ff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question   Group  document\n",
       "0  Cần làm gì khi số liệu thống kê ngành tư pháp ...   Legal  bc1b226c\n",
       "1  Hình thức nào để bổ sung số liệu trong báo cáo...   Legal  bc1b226c\n",
       "2  Thông tin gì cần ghi trong văn bản báo cáo thố...   Legal  bc1b226c\n",
       "3  Ngoài văn bản, có cách nào khác để bổ sung số ...   Legal  bc1b226c\n",
       "4  Báo cáo thống kê ngành tư pháp được xác nhận b...   Legal  bc1b226c\n",
       "5  Các trung tâm cai nghiện rượu hiện nay cung cấ...  Expert  7d3646ff\n",
       "6  Kỹ thuật thay đổi hành vi trong việc cai nghiệ...  Expert  7d3646ff\n",
       "7  Công nghệ cảm biến rượu có tác dụng gì trong đ...  Expert  7d3646ff\n",
       "8  Những hiểu biết mới về chuyển hóa rượu có thể ...  Expert  7d3646ff\n",
       "9  Triệu chứng cai nghiện rượu có thể được ngăn n...  Expert  7d3646ff"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e1e10ea3-fcb9-4620-a308-25f43bb4d6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29133 entries, 0 to 29214\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  29133 non-null  object\n",
      " 1   Group     29133 non-null  object\n",
      " 2   document  29133 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 910.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1df5916c-8178-4f6e-bd9b-d304d398987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_data = pd.concat([df_filtered, df5, df6], axis=0, ignore_index=True)\n",
    "ground_truth_data.to_csv('../data/vietnamese_rag/ground_truth_data/ground_truth_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb55908-9a21-4129-ab61-3d090184da80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
