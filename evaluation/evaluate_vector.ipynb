{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015e7ddf-b1ba-4d46-af17-b02f92541be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94ca7553-c856-4b2b-ae9f-eea8d0f178cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e3e2f5-d5c8-4e37-8eef-b84f0b8d3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_documents(base_path, num_files):\n",
    "#     documents = []\n",
    "#     for i in range(1, num_files + 1):\n",
    "#         file_path = f'{base_path}/documents-with-ids{i}.json'\n",
    "#         with open(file_path, 'rt') as f_in:\n",
    "#             documents.extend(json.load(f_in))\n",
    "#     return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b063a50-e4e2-4e02-9c7c-41abf769292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = '../data/vietnamese_rag'\n",
    "# num_files = 5\n",
    "# documents = load_documents(base_path, num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d751880-4ffb-4c05-b261-4e7243a9ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6d972e0-f866-4d94-bf31-0c9429855aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids1.json', 'rt') as f_in:\n",
    "    documents1 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a8ec2b-33f3-4bd0-be39-860db697dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/text_vector_pickle/text_vector1.pkl', 'rb') as file:\n",
    "    operations1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a53156ca-b84a-4665-b0fc-7f1513609820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(operations1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686c2b32-5213-4295-abd7-783634276960",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(operations1)):\n",
    "    operations1[i]['id'] = documents1[i]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ed235a-0db5-4867-a69a-d70324878483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'75fafd29'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations1[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f55d1853-a3ab-45e1-b11b-6a5a3a55b82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf51673-11fb-430a-bc9e-3f7aeade2647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 1217/1217 [00:35<00:00, 33.94it/s]\n"
     ]
    }
   ],
   "source": [
    "document_question_vector_list = []\n",
    "\n",
    "for doc in tqdm(documents1):\n",
    "    temp_dict = {}\n",
    "    question = doc['question']\n",
    "    temp_dict['question_vector'] = model.encode(question)\n",
    "    document_question_vector_list.append(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f87fe38-9c95-4078-8c4e-b55878a321a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/question_vector_pickle/question_vector1.pkl', 'wb') as file:\n",
    "    pickle.dump(document_question_vector_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cadc6fa3-6f26-4714-a568-8ef3bfaef3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 1217/1217 [00:42<00:00, 28.42it/s]\n"
     ]
    }
   ],
   "source": [
    "document_question_vector_list = []\n",
    "\n",
    "for doc in tqdm(documents1):\n",
    "    temp_dict = {}\n",
    "    answer = doc['answer']\n",
    "    temp_dict['answer_vector'] = model.encode(answer)\n",
    "    document_question_vector_list.append(temp_dict)\n",
    "with open('../data/vietnamese_rag/answer_vector_pickle/answer_vector1.pkl', 'wb') as file:\n",
    "    pickle.dump(document_question_vector_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f069127-6c14-4ce1-8e53-2c544ad157b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_question_vector_list = []\n",
    "\n",
    "for doc in tqdm(documents1):\n",
    "    question = doc['question']\n",
    "    context = doc['context']\n",
    "    answer = doc['answer']\n",
    "    qta = question + ' ' + context + \" \" + answer\n",
    "    temp_dict = {}\n",
    "    temp_dict['question_context_answer_vector'] = model.encode(qta)\n",
    "    document_question_vector_list.append(temp_dict)\n",
    "with open('../data/vietnamese_rag/question_context_answer_vector_pickle/question_context_answer_vector1.pkl', 'wb') as file:\n",
    "    pickle.dump(document_question_vector_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71b98d26-c205-4e2f-8e99-cb6c53e7ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids2.json', 'rt') as f_in:\n",
    "    documents2 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42cce42a-7b05-49e6-86f6-21adbde1ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids3.json', 'rt') as f_in:\n",
    "    documents3 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a11bf0f9-6c92-4f63-a4e3-2597ec9ef796",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids4.json', 'rt') as f_in:\n",
    "    documents4 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae160575-fe78-4bd7-a759-ca0ee29cc7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/vietnamese_rag/documents.json', 'rt') as f_in:\n",
    "#     documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac8433c2-f22c-4ce5-8760-1b73cf519449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in documents:\n",
    "#     if (doc['context'] == None):\n",
    "#         doc['context'] = 'Ngữ cảnh không được cung cấp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "358f7e0b-390f-42b3-bfe0-654ffca6a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in documents4:\n",
    "#     if (doc['context'] == None):\n",
    "#         doc['context'] = 'Ngữ cảnh không được cung cấp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8b1ab95-01c8-47a5-8a12-ffded5008e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/vietnamese_rag/documents-with-ids5.json', 'rt') as f_in:\n",
    "#     documents5 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43fcec85-1df8-4646-bb4e-66718cf9c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in documents5:\n",
    "#     if (doc['context'] == None):\n",
    "#         doc['context'] = 'Ngữ cảnh không được cung cấp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd1f69d9-34b9-46df-9f1a-8163a0e071b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/vietnamese_rag/documents.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(documents, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "430aca80-b98f-4bab-9ae4-0dc1e4e97730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/vietnamese_rag/documents-with-ids4.json', 'wt') as f_out:\n",
    "#     json.dump(documents4 , f_out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b21bb383-19e9-4020-af2b-9679854942e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/vietnamese_rag/documents-with-ids5.json', 'wt') as f_out:\n",
    "#     json.dump(documents5 , f_out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e683b6e0-f4dc-4c4a-994d-03bd716ee014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 1217/1217 [02:26<00:00,  8.33it/s]\n",
      "100%|████████████████| 1217/1217 [02:25<00:00,  8.34it/s]\n",
      " 67%|▋| 811/1217 [01:39<00:49,\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m context \u001b[38;5;241m=\u001b[39m doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m answer \u001b[38;5;241m=\u001b[39m doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 19\u001b[0m qta \u001b[38;5;241m=\u001b[39m \u001b[43mquestion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m answer\n\u001b[1;32m     20\u001b[0m question_vector_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion_vector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(question)\n\u001b[1;32m     21\u001b[0m answer_vector_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_vector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(answer)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "for i in range(2, 6):\n",
    "    document_question_vector_list = []\n",
    "    document_answer_vector_list = []\n",
    "    document_qta_vector_list = []\n",
    "    data = documents2.copy()\n",
    "    if (i == 3):\n",
    "        data = documents3.copy()\n",
    "    elif (i == 4):\n",
    "        data = documents4.copy()\n",
    "    elif (i == 5):\n",
    "        data = documents5.copy()\n",
    "    for doc in tqdm(data):\n",
    "        question_vector_dict = {}\n",
    "        answer_vector_dict = {}\n",
    "        qta_vector_dict = {}\n",
    "        question = doc['question']\n",
    "        context = doc['context']\n",
    "        answer = doc['answer']\n",
    "        qta = question + ' ' + context + \" \" + answer\n",
    "        question_vector_dict['question_vector'] = model.encode(question)\n",
    "        answer_vector_dict['answer_vector'] = model.encode(answer)\n",
    "        qta_vector_dict['question_context_answer_vector'] = model.encode(qta)\n",
    "        document_question_vector_list.append(question_vector_dict)\n",
    "        document_answer_vector_list.append(answer_vector_dict)\n",
    "        document_qta_vector_list.append(qta_vector_dict)\n",
    "    with open(f'../data/vietnamese_rag/question_vector_pickle/question_vector{i}.pkl', 'wb') as file:\n",
    "        pickle.dump(document_question_vector_list, file)\n",
    "    with open(f'../data/vietnamese_rag/answer_vector_pickle/answer_vector{i}.pkl', 'wb') as file:\n",
    "        pickle.dump(document_answer_vector_list, file)\n",
    "    with open(f'../data/vietnamese_rag/question_context_answer_vector_pickle/question_context_answer_vector{i}.pkl', 'wb') as file:\n",
    "        pickle.dump(document_qta_vector_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce452290-b436-4224-a99a-9c74e6a72d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1217/1217 [02:36<00:00,  7.78it/s]\n",
      "100%|███████████████████████████████████████████████| 1221/1221 [02:40<00:00,  7.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 6):\n",
    "    document_question_vector_list = []\n",
    "    document_answer_vector_list = []\n",
    "    document_qta_vector_list = []\n",
    "    data = documents4.copy()\n",
    "    if (i == 5):\n",
    "        data = documents5.copy()\n",
    "    for doc in tqdm(data):\n",
    "        question_vector_dict = {}\n",
    "        answer_vector_dict = {}\n",
    "        qta_vector_dict = {}\n",
    "        question = doc['question']\n",
    "        context = doc['context']\n",
    "        answer = doc['answer']\n",
    "        qta = question + ' ' + context + \" \" + answer\n",
    "        question_vector_dict['question_vector'] = model.encode(question)\n",
    "        answer_vector_dict['answer_vector'] = model.encode(answer)\n",
    "        qta_vector_dict['question_context_answer_vector'] = model.encode(qta)\n",
    "        document_question_vector_list.append(question_vector_dict)\n",
    "        document_answer_vector_list.append(answer_vector_dict)\n",
    "        document_qta_vector_list.append(qta_vector_dict)\n",
    "    with open(f'../data/vietnamese_rag/question_vector_pickle/question_vector{i}.pkl', 'wb') as file:\n",
    "        pickle.dump(document_question_vector_list, file)\n",
    "    with open(f'../data/vietnamese_rag/answer_vector_pickle/answer_vector{i}.pkl', 'wb') as file:\n",
    "        pickle.dump(document_answer_vector_list, file)\n",
    "    with open(f'../data/vietnamese_rag/question_context_answer_vector_pickle/question_context_answer_vector{i}.pkl', 'wb') as file:\n",
    "        pickle.dump(document_qta_vector_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53363b55-f224-41b8-97c2-a330b1fc5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in tqdm(documents):\n",
    "#     question = doc['question']\n",
    "#     context = doc['context']\n",
    "#     answer = doc['answer']\n",
    "#     qta = question + ' ' + context + \" \" + answer\n",
    "\n",
    "#     doc['question_vector'] = model.encode(question)\n",
    "#     doc['context_vector'] = operation\n",
    "#     doc['answer_vector'] = model.encode(answer)\n",
    "#     doc['question_context_answer_vector'] = model.encode(qta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006eac3-74d2-48e4-ad95-ab1d86a7c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(documents)):\n",
    "#     question = documents[i]['question']\n",
    "#     context = documents[i]['context']\n",
    "#     answer = documents[i]['answer']\n",
    "#     qta = question + ' ' + context + \" \" + answer\n",
    "\n",
    "#     documents[i]['question_vector'] = model.encode(question)\n",
    "#     documents[i]['context_vector'] = operations1[i]['text_vector']\n",
    "#     documents[i]['answer_vector'] = model.encode(answer)\n",
    "#     documents[i]['question_context_answer_vector'] = model.encode(qta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9d838-d9ec-4cc5-a6de-155cd2d094df",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
