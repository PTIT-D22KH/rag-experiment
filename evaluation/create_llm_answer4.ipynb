{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0befd402-bf20-42dc-87a9-af8ae218478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a0ca0d-a5af-4448-9c5f-1d834a5a2ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids1.json', 'rt') as f_in:\n",
    "    documents1 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202cf7d6-2ed2-4879-86cd-b8505b5792a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids2.json', 'rt') as f_in:\n",
    "    documents2 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec54e89-1853-43c4-aea9-b207a7c58a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids3.json', 'rt') as f_in:\n",
    "    documents3 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b4810ac-524b-4210-b6ad-6ba8e2deb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids4.json', 'rt') as f_in:\n",
    "    documents4 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b63519-50ed-4e09-b4b8-325d3fab43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids5.json', 'rt') as f_in:\n",
    "    documents5 = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40125567-5f12-4004-9a81-3879b2abd294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def load_documents(base_path, num_files):\n",
    "    documents = []\n",
    "    for i in range(1, num_files + 1):\n",
    "        file_path = f'{base_path}/documents-with-ids{i}.json'\n",
    "        with open(file_path, 'rt') as f_in:\n",
    "            documents.extend(json.load(f_in))\n",
    "    return documents\n",
    "base_path = '../data/vietnamese_rag'\n",
    "num_files = 5\n",
    "documents = load_documents(base_path, num_files)\n",
    "df_ground_truth = pd.read_csv('../data/vietnamese_rag/ground_truth_data/ground_truth_data.csv')\n",
    "\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "doc_idx = {d['id']: d for d in documents}\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d2aefd1-fd0b-4175-8341-ad873eb3a3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'vietnamese-questions'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"group\": {\"type\": \"keyword\"},\n",
    "            \"context\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"answer\": {\"type\": \"text\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"context_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"answer_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_context_answer_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"vietnamese-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a14048-4b72-4bf0-9c32-f775a829f626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████| 6089/6089 [02:20<00:00, 43.46it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_vectors(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def process_documents(documents, index_name, es_client):\n",
    "    full_documents = []\n",
    "    for i in range(1, 6):\n",
    "        if i == 1:\n",
    "            data = documents1.copy()\n",
    "        elif i == 2:\n",
    "            data = documents2.copy()\n",
    "        elif i == 3:\n",
    "            data = documents3.copy()\n",
    "        elif i == 4:\n",
    "            data = documents4.copy()\n",
    "        elif i == 5:\n",
    "            data = documents5.copy()\n",
    "        document_qta_vector_list = load_vectors(f'../data/vietnamese_rag/question_context_answer_vector_pickle/question_context_answer_vector{i}.pkl')\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            data[j]['question_context_answer_vector'] = document_qta_vector_list[j]['question_context_answer_vector']\n",
    "        full_documents.extend(data)\n",
    "    for doc in tqdm(full_documents):\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "process_documents(documents, index_name, es_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da3c5b76-59a6-4d5e-b962-493dfa9290b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, vector, group):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"group\": group\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"group\", \"context\", \"question\", \"answer\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n",
    "def question_context_answer_vector_knn(q):\n",
    "    question = q['question']\n",
    "    group = q['Group']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_context_answer_vector', v_q, group)\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're an assistant working in customer service. Your job is to provide answers to users' questions. Answer the QUESTION based on the CONTEXT from the documents database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION. Provide answer in Vietnamese , in normal text form, not using any markdown form, no need to rewrite the question and make sure that is an answer, not listing questions. Also make sure that the answer provides most information from the CONTEXT as possible .\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"group: {doc['group']}\\nquestion: {doc['question']}\\nanswer: {doc['answer']}\\ncontext: {doc['context'][:1000]}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "client =  Groq(api_key = os.environ['GROQ_API_KEY6'])\n",
    "def llm(prompt, model = 'mixtral-8x7b-32768'):\n",
    "    retries = 5\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model= 'llama3-8b-8192',\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            json_response = response.choices[0].message.content\n",
    "            return json_response\n",
    "        except HTTPError as e:\n",
    "            if e.response.status_code == 429:  # Rate limit error\n",
    "                retry_after = float(e.response.json()['error']['message'].split('in ')[-1].split('s')[0])\n",
    "                time.sleep(retry_after)\n",
    "            else:\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            if i < retries - 1:\n",
    "                time.sleep(2 ** i)  # Exponential backoff\n",
    "            else:\n",
    "                raise\n",
    "# previously: rag(query: str) -> str\n",
    "def rag(query: dict, model='mixtral-8x7b-32768') -> str:\n",
    "    search_results = question_context_answer_vector_knn(query)\n",
    "    prompt = build_prompt(query['question'], search_results)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer\n",
    "pool = ThreadPoolExecutor(max_workers=6)\n",
    "def map_progress(pool, seq, f):\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seq)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for el in seq:\n",
    "            future = pool.submit(f, el)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "def process_record(rec):\n",
    "    model = 'mixtral-8x7b-32768'\n",
    "    answer_llm = rag(rec, model = model)\n",
    "    doc_id = rec['document']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_orig = original_doc['answer']\n",
    "\n",
    "    return {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'group': rec['Group'],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a496a3b-0891-4cce-9f2c-7b45ef9552a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents_current = ground_truth[-1215*5:-1215*4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2431cb75-1ebc-460d-8f44-17f7abfd14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_current = ground_truth[-1215*4:-1215*3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f02a158b-36f8-4a6f-8a75-883c67dad415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 0 15\n",
      "245 15 30\n",
      "246 30 45\n",
      "247 45 60\n",
      "248 60 75\n",
      "249 75 90\n",
      "250 90 105\n",
      "251 105 120\n",
      "252 120 135\n",
      "253 135 150\n",
      "254 150 165\n",
      "255 165 180\n",
      "256 180 195\n",
      "257 195 210\n",
      "258 210 225\n",
      "259 225 240\n",
      "260 240 255\n",
      "261 255 270\n",
      "262 270 285\n",
      "263 285 300\n",
      "264 300 315\n",
      "265 315 330\n",
      "266 330 345\n",
      "267 345 360\n",
      "268 360 375\n",
      "269 375 390\n",
      "270 390 405\n",
      "271 405 420\n",
      "272 420 435\n",
      "273 435 450\n",
      "274 450 465\n",
      "275 465 480\n",
      "276 480 495\n",
      "277 495 510\n",
      "278 510 525\n",
      "279 525 540\n",
      "280 540 555\n",
      "281 555 570\n",
      "282 570 585\n",
      "283 585 600\n",
      "284 600 615\n",
      "285 615 630\n",
      "286 630 645\n",
      "287 645 660\n",
      "288 660 675\n",
      "289 675 690\n",
      "290 690 705\n",
      "291 705 720\n",
      "292 720 735\n",
      "293 735 750\n",
      "294 750 765\n",
      "295 765 780\n",
      "296 780 795\n",
      "297 795 810\n",
      "298 810 825\n",
      "299 825 840\n",
      "300 840 855\n",
      "301 855 870\n",
      "302 870 885\n",
      "303 885 900\n",
      "304 900 915\n",
      "305 915 930\n",
      "306 930 945\n",
      "307 945 960\n",
      "308 960 975\n",
      "309 975 990\n",
      "310 990 1005\n",
      "311 1005 1020\n",
      "312 1020 1035\n",
      "313 1035 1050\n",
      "314 1050 1065\n",
      "315 1065 1080\n",
      "316 1080 1095\n",
      "317 1095 1110\n",
      "318 1110 1125\n",
      "319 1125 1140\n",
      "320 1140 1155\n",
      "321 1155 1170\n",
      "322 1170 1185\n",
      "323 1185 1200\n",
      "324 1200 1216\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 15\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents_current) // chunk_size)   # Ending chunk index\n",
    "# print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = []\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    if (i == end_chunk - 1):\n",
    "        chunk_end = chunk_start + chunk_size + 1\n",
    "    print(i + 244, chunk_start, chunk_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad88092-d899-4bca-b4c0-8f214b906728",
   "metadata": {},
   "source": [
    "## 163, 244, 325"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15aa950-1699-4cca-9db8-58e5a045e1d3",
   "metadata": {},
   "source": [
    " ## +81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f3a81d5-86c2-4948-bcb9-4dad1adeb357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [00:28<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 44 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last288.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:22<00:00,  5.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 45 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last289.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:36<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 46 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last290.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:24<00:00,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 47 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last291.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [02:01<00:00,  8.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 48 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last292.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:19<00:00,  5.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 49 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last293.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:30<00:00,  6.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 50 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last294.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:45<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 51 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last295.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:31<00:00,  6.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 52 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last296.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:16<00:00,  5.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 53 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last297.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [00:56<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 54 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last298.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:21<00:00,  5.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 55 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last299.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [02:02<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 56 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last300.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:30<00:00,  6.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 57 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last301.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:03<00:00,  4.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 58 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last302.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:40<00:00,  6.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 59 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last303.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:32<00:00,  6.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 60 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last304.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:14<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 61 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last305.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:33<00:00,  6.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 62 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last306.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:28<00:00,  5.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 63 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last307.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:35<00:00,  6.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 64 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last308.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:33<00:00,  6.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 65 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last309.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:25<00:00,  5.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 66 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last310.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:25<00:00,  5.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 67 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last311.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:37<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 68 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last312.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:04<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 69 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last313.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:48<00:00,  7.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 70 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last314.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:27<00:00,  5.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 71 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last315.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:45<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 72 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last316.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:14<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 73 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last317.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [00:57<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 74 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last318.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:58<00:00,  7.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 75 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last319.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:07<00:00,  4.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 76 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last320.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:38<00:00,  6.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 77 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last321.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:44<00:00,  6.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 78 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last322.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:25<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 79 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last323.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:14<00:00,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 80 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last324.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 15\n",
    "start_chunk = 44 # Starting chunk index\n",
    "end_chunk = (len(documents_current) // chunk_size)   # Ending chunk index\n",
    "# print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = []\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    if (i == end_chunk - 1):\n",
    "        chunk_end = chunk_start + chunk_size + 1\n",
    "    # print(i + 1, chunk_start, chunk_end)\n",
    "    chunk = documents_current[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_record)\n",
    "    results.extend(processed_results)\n",
    "    # # Store the results incrementally\n",
    "    # for result in processed_results:\n",
    "    #     if result is not None:\n",
    "    #         doc_id, questions = result\n",
    "    #         results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/llm_answer/llm_answer_last{i + 244}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    # print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    # time.sleep(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "486da5b7-db80-427a-b93c-d628c237c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_current = ground_truth[-1215*8:-1215*7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93de859-ff35-4772-b170-d7e41d90f6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [01:41<00:00,  6.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 36 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last604.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [00:58<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 37 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last605.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 15/15 [02:18<00:00,  9.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 38 processed and saved to ../data/vietnamese_rag/llm_answer/llm_answer_last606.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                     | 0/15 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "chunk_size = 15\n",
    "start_chunk = 36 # Starting chunk index\n",
    "end_chunk = (len(documents_current) // chunk_size)   # Ending chunk index\n",
    "# print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = []\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    if (i == end_chunk - 1):\n",
    "        chunk_end = chunk_start + chunk_size + 1\n",
    "    # print(i + 1, chunk_start, chunk_end)\n",
    "    chunk = documents_current[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_record)\n",
    "    results.extend(processed_results)\n",
    "    # # Store the results incrementally\n",
    "    # for result in processed_results:\n",
    "    #     if result is not None:\n",
    "    #         doc_id, questions = result\n",
    "    #         results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/llm_answer/llm_answer_last{i + 568}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "    # print(results)\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    # time.sleep(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e2c32-2002-4e44-80f9-499e1254884e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
